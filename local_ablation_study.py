#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æœ¬åœ°æ¶ˆèå®éªŒï¼šä½¿ç”¨ç°æœ‰äººè„¸æ•°æ®åº“æµ‹è¯•test.pyç®—æ³•å„æ¨¡å—æ•ˆæœ

å®éªŒç›®çš„ï¼š
1. éªŒè¯ç¯å¢ƒæ„ŸçŸ¥åé¦ˆç³»ç»Ÿçš„æœ‰æ•ˆæ€§
2. éªŒè¯è‡ªç›‘ç£å­¦ä¹ æœºåˆ¶çš„è´¡çŒ®
3. éªŒè¯å¤šå°ºåº¦é‡‘å­—å¡”æ£€æµ‹çš„æ€§èƒ½æå‡
4. éªŒè¯æ™ºèƒ½å›¾åƒå¢å¼ºçš„æ•ˆæœ
5. å¯¹æ¯”å„æ¨¡å—ç»„åˆçš„æ€§èƒ½è¡¨ç°
"""

import os
import cv2
import dlib
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
import time
import pickle
from pathlib import Path
import random
from collections import defaultdict
import warnings
warnings.filterwarnings('ignore')

class LocalAblationStudy:
    """æœ¬åœ°æ¶ˆèå®éªŒç±»"""
    
    def __init__(self, database_path="data/database_faces"):
        self.database_path = Path(database_path)
        
        # åˆå§‹åŒ–dlibæ¨¡å‹
        try:
            self.detector = dlib.get_frontal_face_detector()
            self.predictor = dlib.shape_predictor("data/data_dlib/shape_predictor_68_face_landmarks.dat")
            self.face_rec = dlib.face_recognition_model_v1("data/data_dlib/dlib_face_recognition_resnet_model_v1.dat")
            print("âœ… dlibæ¨¡å‹åŠ è½½æˆåŠŸ")
        except Exception as e:
            print(f"âŒ dlibæ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return
        
        # å®éªŒç»“æœå­˜å‚¨
        self.results = defaultdict(dict)
        
        print("ğŸ”¬ æœ¬åœ°æ¶ˆèå®éªŒåˆå§‹åŒ–å®Œæˆ")
    
    def load_local_dataset(self):
        """åŠ è½½æœ¬åœ°äººè„¸æ•°æ®åº“"""
        print("ğŸ“š åŠ è½½æœ¬åœ°äººè„¸æ•°æ®åº“...")
        
        if not self.database_path.exists():
            print(f"âŒ æ•°æ®åº“è·¯å¾„ä¸å­˜åœ¨: {self.database_path}")
            return None, None
        
        # æ”¶é›†æ‰€æœ‰äººè„¸æ•°æ®
        all_data = []
        person_count = 0
        
        for person_dir in self.database_path.iterdir():
            if person_dir.is_dir() and not person_dir.name.startswith('.'):
                images = list(person_dir.glob("*.jpg")) + list(person_dir.glob("*.jpeg")) + list(person_dir.glob("*.png"))
                
                if len(images) >= 2:  # è‡³å°‘éœ€è¦2å¼ å›¾ç‰‡
                    person_name = person_dir.name
                    for img_path in images:
                        all_data.append((str(img_path), person_name))
                    person_count += 1
                    print(f"  ğŸ“ {person_name}: {len(images)} å¼ å›¾ç‰‡")
        
        print(f"âœ… åŠ è½½å®Œæˆ: {person_count} ä¸ªèº«ä»½ï¼Œå…± {len(all_data)} å¼ å›¾ç‰‡")
        
        if len(all_data) < 10:
            print("âŒ æ•°æ®é‡ä¸è¶³ï¼Œè‡³å°‘éœ€è¦10å¼ å›¾ç‰‡")
            return None, None
        
        # æŒ‰èº«ä»½åˆ†å‰²è®­ç»ƒå’Œæµ‹è¯•æ•°æ®
        train_data = []
        test_data = []
        
        # æŒ‰èº«ä»½åˆ†ç»„
        person_images = defaultdict(list)
        for img_path, person_name in all_data:
            person_images[person_name].append(img_path)
        
        # ä¸ºæ¯ä¸ªèº«ä»½åˆ†é…è®­ç»ƒå’Œæµ‹è¯•æ•°æ®
        for person_name, images in person_images.items():
            if len(images) >= 2:
                # éšæœºæ‰“ä¹±
                random.shuffle(images)
                
                # 70%ç”¨äºè®­ç»ƒï¼Œ30%ç”¨äºæµ‹è¯•
                split_idx = max(1, int(len(images) * 0.7))
                
                for img_path in images[:split_idx]:
                    train_data.append((img_path, person_name, 'train'))
                
                for img_path in images[split_idx:]:
                    test_data.append((img_path, person_name, 'test'))
        
        print(f"ğŸ“Š æ•°æ®åˆ†å‰²: è®­ç»ƒé›† {len(train_data)} å¼ ï¼Œæµ‹è¯•é›† {len(test_data)} å¼ ")
        
        return train_data, test_data
    
    def extract_face_features(self, image_path, enhancement=False, multiscale=False):
        """æå–äººè„¸ç‰¹å¾"""
        try:
            image = cv2.imread(image_path)
            if image is None:
                print(f"âš ï¸ æ— æ³•è¯»å–å›¾ç‰‡: {image_path}")
                return None
            
            # å›¾åƒå¢å¼ºï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if enhancement:
                image = self.enhance_image(image)
            
            # äººè„¸æ£€æµ‹
            if multiscale:
                faces = self.detect_faces_multiscale(image)
                if not faces:
                    return None
                face_rect = faces[0][0]  # å–ç¬¬ä¸€ä¸ªæ£€æµ‹ç»“æœ
            else:
                faces = self.detector(image)
                if len(faces) == 0:
                    return None
                face_rect = faces[0]
            
            # ç‰¹å¾ç‚¹æ£€æµ‹
            landmarks = self.predictor(image, face_rect)
            
            # ç‰¹å¾æå–
            face_descriptor = self.face_rec.compute_face_descriptor(image, landmarks)
            
            return np.array(face_descriptor)
        
        except Exception as e:
            print(f"âš ï¸ ç‰¹å¾æå–å¤±è´¥ {image_path}: {e}")
            return None
    
    def enhance_image(self, image):
        """æ™ºèƒ½å›¾åƒå¢å¼º"""
        # è¯„ä¼°å…‰ç…§æ¡ä»¶
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        brightness = np.mean(hsv[:, :, 2]) / 255.0
        
        if brightness < 0.4:  # ä½å…‰ç…§æ¡ä»¶
            # è½¬æ¢åˆ°LABè‰²å½©ç©ºé—´
            lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)
            
            # CLAHEå¢å¼º
            clip_limit = 2.0 + (0.4 - brightness) * 5.0
            clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=(8, 8))
            l = clahe.apply(l)
            
            # Gammaæ ¡æ­£
            gamma = 0.6 + brightness * 0.8
            l = np.power(l / 255.0, gamma) * 255.0
            l = np.uint8(l)
            
            # é‡æ–°ç»„åˆ
            enhanced_lab = cv2.merge([l, a, b])
            enhanced_image = cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2BGR)
            
            return enhanced_image
        
        return image
    
    def detect_faces_multiscale(self, image):
        """å¤šå°ºåº¦äººè„¸æ£€æµ‹"""
        all_faces = []
        scales = [0.7, 0.85, 1.0, 1.15, 1.3]
        
        for scale in scales:
            height, width = image.shape[:2]
            new_height, new_width = int(height * scale), int(width * scale)
            
            if new_height > 50 and new_width > 50:  # ç¡®ä¿å›¾åƒä¸ä¼šå¤ªå°
                scaled_image = cv2.resize(image, (new_width, new_height))
                
                faces = self.detector(scaled_image)
                
                for face in faces:
                    scaled_face = dlib.rectangle(
                        int(face.left() / scale),
                        int(face.top() / scale),
                        int(face.right() / scale),
                        int(face.bottom() / scale)
                    )
                    all_faces.append((scaled_face, scale))
        
        return all_faces
    
    def cosine_similarity(self, vec1, vec2):
        """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦"""
        dot_product = np.dot(vec1, vec2)
        norm1 = np.linalg.norm(vec1)
        norm2 = np.linalg.norm(vec2)
        
        if norm1 == 0 or norm2 == 0:
            return 0
        
        return dot_product / (norm1 * norm2)
    
    def run_baseline_experiment(self, train_data, test_data):
        """åŸºçº¿å®éªŒï¼šä¼ ç»Ÿäººè„¸è¯†åˆ«"""
        print("\nğŸ”¬ è¿è¡ŒåŸºçº¿å®éªŒï¼ˆä¼ ç»Ÿç®—æ³•ï¼‰...")
        
        # æ„å»ºç‰¹å¾æ•°æ®åº“
        feature_db = {}
        successful_extractions = 0
        
        print("ğŸ“š æ„å»ºç‰¹å¾æ•°æ®åº“...")
        for img_path, person_name, _ in train_data:
            feature = self.extract_face_features(img_path, enhancement=False, multiscale=False)
            if feature is not None:
                if person_name not in feature_db:
                    feature_db[person_name] = []
                feature_db[person_name].append(feature)
                successful_extractions += 1
        
        print(f"âœ… æˆåŠŸæå– {successful_extractions}/{len(train_data)} ä¸ªè®­ç»ƒç‰¹å¾")
        
        # æµ‹è¯•è¯†åˆ«
        print("ğŸ§ª å¼€å§‹è¯†åˆ«æµ‹è¯•...")
        predictions = []
        true_labels = []
        processing_times = []
        confidences = []
        
        for img_path, true_label, _ in test_data:
            start_time = time.time()
            
            test_feature = self.extract_face_features(img_path, enhancement=False, multiscale=False)
            
            if test_feature is not None:
                best_match = None
                best_similarity = 0
                threshold = 0.6  # å›ºå®šé˜ˆå€¼
                
                for person_name, features in feature_db.items():
                    for db_feature in features:
                        similarity = self.cosine_similarity(test_feature, db_feature)
                        if similarity > threshold and similarity > best_similarity:
                            best_similarity = similarity
                            best_match = person_name
                
                predictions.append(best_match if best_match else "Unknown")
                confidences.append(best_similarity)
            else:
                predictions.append("Unknown")
                confidences.append(0)
            
            true_labels.append(true_label)
            processing_times.append(time.time() - start_time)
        
        # è®¡ç®—æŒ‡æ ‡
        accuracy = accuracy_score(true_labels, predictions)
        avg_time = np.mean(processing_times)
        avg_confidence = np.mean(confidences)
        
        # è®¡ç®—è¯†åˆ«æˆåŠŸçš„æ ·æœ¬çš„ç½®ä¿¡åº¦
        successful_confidences = [conf for pred, conf in zip(predictions, confidences) if pred != "Unknown"]
        avg_successful_confidence = np.mean(successful_confidences) if successful_confidences else 0
        
        self.results['baseline'] = {
            'accuracy': accuracy,
            'avg_processing_time': avg_time,
            'avg_confidence': avg_confidence,
            'avg_successful_confidence': avg_successful_confidence,
            'predictions': predictions,
            'true_labels': true_labels,
            'detection_rate': len([p for p in predictions if p != "Unknown"]) / len(predictions)
        }
        
        print(f"âœ… åŸºçº¿å®éªŒå®Œæˆ")
        print(f"   ğŸ“Š å‡†ç¡®ç‡: {accuracy:.3f}")
        print(f"   â±ï¸ å¹³å‡å¤„ç†æ—¶é—´: {avg_time:.3f}s")
        print(f"   ğŸ¯ å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.3f}")
        print(f"   ğŸ” æ£€æµ‹æˆåŠŸç‡: {self.results['baseline']['detection_rate']:.3f}")
        
        return accuracy, avg_time
    
    def run_enhancement_experiment(self, train_data, test_data):
        """å›¾åƒå¢å¼ºæ¨¡å—å®éªŒ"""
        print("\nğŸ”¬ è¿è¡Œå›¾åƒå¢å¼ºå®éªŒ...")
        
        # æ„å»ºç‰¹å¾æ•°æ®åº“ï¼ˆä½¿ç”¨å¢å¼ºï¼‰
        feature_db = {}
        successful_extractions = 0
        
        for img_path, person_name, _ in train_data:
            feature = self.extract_face_features(img_path, enhancement=True, multiscale=False)
            if feature is not None:
                if person_name not in feature_db:
                    feature_db[person_name] = []
                feature_db[person_name].append(feature)
                successful_extractions += 1
        
        print(f"âœ… æˆåŠŸæå– {successful_extractions}/{len(train_data)} ä¸ªè®­ç»ƒç‰¹å¾")
        
        # æµ‹è¯•è¯†åˆ«
        predictions = []
        true_labels = []
        processing_times = []
        confidences = []
        
        for img_path, true_label, _ in test_data:
            start_time = time.time()
            
            test_feature = self.extract_face_features(img_path, enhancement=True, multiscale=False)
            
            if test_feature is not None:
                best_match = None
                best_similarity = 0
                threshold = 0.6
                
                for person_name, features in feature_db.items():
                    for db_feature in features:
                        similarity = self.cosine_similarity(test_feature, db_feature)
                        if similarity > threshold and similarity > best_similarity:
                            best_similarity = similarity
                            best_match = person_name
                
                predictions.append(best_match if best_match else "Unknown")
                confidences.append(best_similarity)
            else:
                predictions.append("Unknown")
                confidences.append(0)
            
            true_labels.append(true_label)
            processing_times.append(time.time() - start_time)
        
        accuracy = accuracy_score(true_labels, predictions)
        avg_time = np.mean(processing_times)
        avg_confidence = np.mean(confidences)
        
        successful_confidences = [conf for pred, conf in zip(predictions, confidences) if pred != "Unknown"]
        avg_successful_confidence = np.mean(successful_confidences) if successful_confidences else 0
        
        self.results['enhancement'] = {
            'accuracy': accuracy,
            'avg_processing_time': avg_time,
            'avg_confidence': avg_confidence,
            'avg_successful_confidence': avg_successful_confidence,
            'predictions': predictions,
            'true_labels': true_labels,
            'detection_rate': len([p for p in predictions if p != "Unknown"]) / len(predictions)
        }
        
        print(f"âœ… å›¾åƒå¢å¼ºå®éªŒå®Œæˆ")
        print(f"   ğŸ“Š å‡†ç¡®ç‡: {accuracy:.3f}")
        print(f"   â±ï¸ å¹³å‡å¤„ç†æ—¶é—´: {avg_time:.3f}s")
        print(f"   ğŸ¯ å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.3f}")
        print(f"   ğŸ” æ£€æµ‹æˆåŠŸç‡: {self.results['enhancement']['detection_rate']:.3f}")
        
        return accuracy, avg_time
    
    def run_multiscale_experiment(self, train_data, test_data):
        """å¤šå°ºåº¦æ£€æµ‹å®éªŒ"""
        print("\nğŸ”¬ è¿è¡Œå¤šå°ºåº¦æ£€æµ‹å®éªŒ...")
        
        # æ„å»ºç‰¹å¾æ•°æ®åº“
        feature_db = {}
        successful_extractions = 0
        
        for img_path, person_name, _ in train_data:
            feature = self.extract_face_features(img_path, enhancement=False, multiscale=True)
            if feature is not None:
                if person_name not in feature_db:
                    feature_db[person_name] = []
                feature_db[person_name].append(feature)
                successful_extractions += 1
        
        print(f"âœ… æˆåŠŸæå– {successful_extractions}/{len(train_data)} ä¸ªè®­ç»ƒç‰¹å¾")
        
        # æµ‹è¯•è¯†åˆ«
        predictions = []
        true_labels = []
        processing_times = []
        confidences = []
        
        for img_path, true_label, _ in test_data:
            start_time = time.time()
            
            test_feature = self.extract_face_features(img_path, enhancement=False, multiscale=True)
            
            if test_feature is not None:
                best_match = None
                best_similarity = 0
                threshold = 0.6
                
                for person_name, features in feature_db.items():
                    for db_feature in features:
                        similarity = self.cosine_similarity(test_feature, db_feature)
                        if similarity > threshold and similarity > best_similarity:
                            best_similarity = similarity
                            best_match = person_name
                
                predictions.append(best_match if best_match else "Unknown")
                confidences.append(best_similarity)
            else:
                predictions.append("Unknown")
                confidences.append(0)
            
            true_labels.append(true_label)
            processing_times.append(time.time() - start_time)
        
        accuracy = accuracy_score(true_labels, predictions)
        avg_time = np.mean(processing_times)
        avg_confidence = np.mean(confidences)
        
        successful_confidences = [conf for pred, conf in zip(predictions, confidences) if pred != "Unknown"]
        avg_successful_confidence = np.mean(successful_confidences) if successful_confidences else 0
        
        self.results['multiscale'] = {
            'accuracy': accuracy,
            'avg_processing_time': avg_time,
            'avg_confidence': avg_confidence,
            'avg_successful_confidence': avg_successful_confidence,
            'predictions': predictions,
            'true_labels': true_labels,
            'detection_rate': len([p for p in predictions if p != "Unknown"]) / len(predictions)
        }
        
        print(f"âœ… å¤šå°ºåº¦æ£€æµ‹å®éªŒå®Œæˆ")
        print(f"   ğŸ“Š å‡†ç¡®ç‡: {accuracy:.3f}")
        print(f"   â±ï¸ å¹³å‡å¤„ç†æ—¶é—´: {avg_time:.3f}s")
        print(f"   ğŸ¯ å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.3f}")
        print(f"   ğŸ” æ£€æµ‹æˆåŠŸç‡: {self.results['multiscale']['detection_rate']:.3f}")
        
        return accuracy, avg_time
    
    def run_full_enhanced_experiment(self, train_data, test_data):
        """å®Œæ•´å¢å¼ºç®—æ³•å®éªŒ"""
        print("\nğŸ”¬ è¿è¡Œå®Œæ•´å¢å¼ºç®—æ³•å®éªŒ...")
        
        # æ„å»ºç‰¹å¾æ•°æ®åº“
        feature_db = {}
        feature_buffer = {}  # è‡ªç›‘ç£å­¦ä¹ ç¼“å†²åŒº
        successful_extractions = 0
        
        for img_path, person_name, _ in train_data:
            feature = self.extract_face_features(img_path, enhancement=True, multiscale=True)
            if feature is not None:
                if person_name not in feature_db:
                    feature_db[person_name] = []
                    feature_buffer[person_name] = []
                feature_db[person_name].append(feature)
                feature_buffer[person_name].append(feature)
                successful_extractions += 1
        
        print(f"âœ… æˆåŠŸæå– {successful_extractions}/{len(train_data)} ä¸ªè®­ç»ƒç‰¹å¾")
        
        # æµ‹è¯•è¯†åˆ«ï¼ˆå¸¦è‡ªé€‚åº”é˜ˆå€¼å’Œè‡ªç›‘ç£å­¦ä¹ ï¼‰
        predictions = []
        true_labels = []
        processing_times = []
        confidences = []
        
        # ç¯å¢ƒæ„ŸçŸ¥å‚æ•°
        lighting_history = []
        adaptive_threshold = 0.6
        
        for img_path, true_label, _ in test_data:
            start_time = time.time()
            
            # è¯„ä¼°å½“å‰å›¾åƒçš„å…‰ç…§æ¡ä»¶
            image = cv2.imread(img_path)
            if image is not None:
                hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
                brightness = np.mean(hsv[:, :, 2]) / 255.0
                lighting_history.append(brightness)
                
                # ä¿æŒæœ€è¿‘10æ¬¡çš„å…‰ç…§å†å²
                if len(lighting_history) > 10:
                    lighting_history.pop(0)
                
                # æ ¹æ®å…‰ç…§å†å²è°ƒæ•´é˜ˆå€¼
                avg_lighting = np.mean(lighting_history)
                if avg_lighting < 0.3:  # ä½å…‰ç…§
                    adaptive_threshold = 0.55
                elif avg_lighting > 0.7:  # é«˜å…‰ç…§
                    adaptive_threshold = 0.65
                else:  # æ­£å¸¸å…‰ç…§
                    adaptive_threshold = 0.6
            
            test_feature = self.extract_face_features(img_path, enhancement=True, multiscale=True)
            
            if test_feature is not None:
                best_match = None
                best_similarity = 0
                
                for person_name, features in feature_db.items():
                    # è®¡ç®—ä¸æ•°æ®åº“ç‰¹å¾çš„ç›¸ä¼¼åº¦
                    db_similarities = [self.cosine_similarity(test_feature, db_feat) 
                                     for db_feat in features]
                    db_similarity = max(db_similarities) if db_similarities else 0
                    
                    # è®¡ç®—ä¸ç¼“å†²åŒºç‰¹å¾çš„ç›¸ä¼¼åº¦ï¼ˆè‡ªç›‘ç£å­¦ä¹ ï¼‰
                    if person_name in feature_buffer and feature_buffer[person_name]:
                        buffer_similarities = [self.cosine_similarity(test_feature, buf_feat) 
                                             for buf_feat in feature_buffer[person_name]]
                        buffer_similarity = max(buffer_similarities)
                    else:
                        buffer_similarity = 0
                    
                    # èåˆç›¸ä¼¼åº¦ï¼ˆæ•°æ®åº“æƒé‡æ›´é«˜ï¼‰
                    final_similarity = 0.75 * db_similarity + 0.25 * buffer_similarity
                    
                    if final_similarity > adaptive_threshold and final_similarity > best_similarity:
                        best_similarity = final_similarity
                        best_match = person_name
                
                predictions.append(best_match if best_match else "Unknown")
                confidences.append(best_similarity)
                
                # æ›´æ–°ç‰¹å¾ç¼“å†²åŒºï¼ˆè‡ªç›‘ç£å­¦ä¹ ï¼‰
                if best_match and best_similarity > 0.7:
                    if len(feature_buffer[best_match]) > 15:  # é™åˆ¶ç¼“å†²åŒºå¤§å°
                        feature_buffer[best_match].pop(0)
                    feature_buffer[best_match].append(test_feature)
            else:
                predictions.append("Unknown")
                confidences.append(0)
            
            true_labels.append(true_label)
            processing_times.append(time.time() - start_time)
        
        accuracy = accuracy_score(true_labels, predictions)
        avg_time = np.mean(processing_times)
        avg_confidence = np.mean(confidences)
        
        successful_confidences = [conf for pred, conf in zip(predictions, confidences) if pred != "Unknown"]
        avg_successful_confidence = np.mean(successful_confidences) if successful_confidences else 0
        
        self.results['full_enhanced'] = {
            'accuracy': accuracy,
            'avg_processing_time': avg_time,
            'avg_confidence': avg_confidence,
            'avg_successful_confidence': avg_successful_confidence,
            'predictions': predictions,
            'true_labels': true_labels,
            'detection_rate': len([p for p in predictions if p != "Unknown"]) / len(predictions),
            'adaptive_threshold_final': adaptive_threshold
        }
        
        print(f"âœ… å®Œæ•´å¢å¼ºç®—æ³•å®éªŒå®Œæˆ")
        print(f"   ğŸ“Š å‡†ç¡®ç‡: {accuracy:.3f}")
        print(f"   â±ï¸ å¹³å‡å¤„ç†æ—¶é—´: {avg_time:.3f}s")
        print(f"   ğŸ¯ å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.3f}")
        print(f"   ğŸ” æ£€æµ‹æˆåŠŸç‡: {self.results['full_enhanced']['detection_rate']:.3f}")
        print(f"   ğŸ›ï¸ æœ€ç»ˆè‡ªé€‚åº”é˜ˆå€¼: {adaptive_threshold:.3f}")
        
        return accuracy, avg_time, avg_confidence
    
    def generate_report(self):
        """ç”Ÿæˆå®éªŒæŠ¥å‘Š"""
        print("\nğŸ“Š ç”Ÿæˆæ¶ˆèå®éªŒæŠ¥å‘Š...")
        
        # åˆ›å»ºç»“æœå¯¹æ¯”è¡¨
        comparison_data = []
        exp_names_cn = {
            'baseline': 'åŸºçº¿ç®—æ³•',
            'enhancement': 'å›¾åƒå¢å¼º',
            'multiscale': 'å¤šå°ºåº¦æ£€æµ‹',
            'full_enhanced': 'å®Œæ•´å¢å¼ºç®—æ³•'
        }
        
        for exp_name, results in self.results.items():
            comparison_data.append({
                'å®éªŒé…ç½®': exp_names_cn.get(exp_name, exp_name),
                'å‡†ç¡®ç‡': f"{results['accuracy']:.3f}",
                'æ£€æµ‹æˆåŠŸç‡': f"{results['detection_rate']:.3f}",
                'å¹³å‡å¤„ç†æ—¶é—´(s)': f"{results['avg_processing_time']:.3f}",
                'å¹³å‡ç½®ä¿¡åº¦': f"{results['avg_confidence']:.3f}",
                'æˆåŠŸè¯†åˆ«ç½®ä¿¡åº¦': f"{results['avg_successful_confidence']:.3f}"
            })
        
        df = pd.DataFrame(comparison_data)
        
        # ä¿å­˜ç»“æœ
        df.to_csv('local_ablation_results.csv', index=False, encoding='utf-8-sig')
        
        # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
        self.plot_results()
        
        # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        self.generate_detailed_report(df)
        
        print("âœ… å®éªŒæŠ¥å‘Šç”Ÿæˆå®Œæˆ")
        
        return df
    
    def plot_results(self):
        """ç»˜åˆ¶ç»“æœå›¾è¡¨"""
        plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        fig, axes = plt.subplots(2, 3, figsize=(18, 12))
        
        exp_names = list(self.results.keys())
        exp_names_cn = ['åŸºçº¿ç®—æ³•', 'å›¾åƒå¢å¼º', 'å¤šå°ºåº¦æ£€æµ‹', 'å®Œæ•´å¢å¼ºç®—æ³•']
        colors = ['#ff7f0e', '#2ca02c', '#d62728', '#1f77b4']
        
        # 1. å‡†ç¡®ç‡å¯¹æ¯”
        accuracies = [self.results[name]['accuracy'] for name in exp_names]
        bars1 = axes[0, 0].bar(exp_names_cn, accuracies, color=colors)
        axes[0, 0].set_title('å‡†ç¡®ç‡å¯¹æ¯”', fontsize=14, fontweight='bold')
        axes[0, 0].set_ylabel('å‡†ç¡®ç‡')
        axes[0, 0].set_ylim(0, 1)
        for i, v in enumerate(accuracies):
            axes[0, 0].text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')
        
        # 2. æ£€æµ‹æˆåŠŸç‡å¯¹æ¯”
        detection_rates = [self.results[name]['detection_rate'] for name in exp_names]
        bars2 = axes[0, 1].bar(exp_names_cn, detection_rates, color=colors)
        axes[0, 1].set_title('æ£€æµ‹æˆåŠŸç‡å¯¹æ¯”', fontsize=14, fontweight='bold')
        axes[0, 1].set_ylabel('æ£€æµ‹æˆåŠŸç‡')
        axes[0, 1].set_ylim(0, 1)
        for i, v in enumerate(detection_rates):
            axes[0, 1].text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')
        
        # 3. å¤„ç†æ—¶é—´å¯¹æ¯”
        times = [self.results[name]['avg_processing_time'] for name in exp_names]
        bars3 = axes[0, 2].bar(exp_names_cn, times, color=colors)
        axes[0, 2].set_title('å¹³å‡å¤„ç†æ—¶é—´å¯¹æ¯”', fontsize=14, fontweight='bold')
        axes[0, 2].set_ylabel('å¤„ç†æ—¶é—´ (ç§’)')
        for i, v in enumerate(times):
            axes[0, 2].text(i, v + 0.001, f'{v:.3f}', ha='center', va='bottom')
        
        # 4. æ€§èƒ½æå‡ç™¾åˆ†æ¯”
        baseline_acc = self.results['baseline']['accuracy']
        improvements = [(self.results[name]['accuracy'] - baseline_acc) / baseline_acc * 100 
                       for name in exp_names]
        
        improvement_colors = ['gray' if imp <= 0 else 'green' for imp in improvements]
        bars4 = axes[1, 0].bar(exp_names_cn, improvements, color=improvement_colors)
        axes[1, 0].set_title('ç›¸å¯¹åŸºçº¿çš„å‡†ç¡®ç‡æå‡ (%)', fontsize=14, fontweight='bold')
        axes[1, 0].set_ylabel('æå‡ç™¾åˆ†æ¯” (%)')
        axes[1, 0].axhline(y=0, color='black', linestyle='-', alpha=0.3)
        for i, v in enumerate(improvements):
            axes[1, 0].text(i, v + 0.5, f'{v:.1f}%', ha='center', va='bottom')
        
        # 5. ç½®ä¿¡åº¦å¯¹æ¯”
        confidences = [self.results[name]['avg_successful_confidence'] for name in exp_names]
        bars5 = axes[1, 1].bar(exp_names_cn, confidences, color=colors)
        axes[1, 1].set_title('æˆåŠŸè¯†åˆ«å¹³å‡ç½®ä¿¡åº¦', fontsize=14, fontweight='bold')
        axes[1, 1].set_ylabel('ç½®ä¿¡åº¦')
        axes[1, 1].set_ylim(0, 1)
        for i, v in enumerate(confidences):
            axes[1, 1].text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')
        
        # 6. ç»¼åˆæ€§èƒ½é›·è¾¾å›¾
        categories = ['å‡†ç¡®ç‡', 'æ£€æµ‹ç‡', 'ç½®ä¿¡åº¦', 'é€Ÿåº¦']
        
        # å½’ä¸€åŒ–æ•°æ®ï¼ˆé€Ÿåº¦å–å€’æ•°å¹¶å½’ä¸€åŒ–ï¼‰
        max_time = max(times)
        normalized_data = {
            'åŸºçº¿ç®—æ³•': [accuracies[0], detection_rates[0], confidences[0], (max_time - times[0]) / max_time],
            'å®Œæ•´å¢å¼ºç®—æ³•': [accuracies[3], detection_rates[3], confidences[3], (max_time - times[3]) / max_time]
        }
        
        angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()
        angles += angles[:1]  # é—­åˆå›¾å½¢
        
        ax_radar = plt.subplot(2, 3, 6, projection='polar')
        
        for name, values in normalized_data.items():
            values += values[:1]  # é—­åˆå›¾å½¢
            ax_radar.plot(angles, values, 'o-', linewidth=2, label=name)
            ax_radar.fill(angles, values, alpha=0.25)
        
        ax_radar.set_xticks(angles[:-1])
        ax_radar.set_xticklabels(categories)
        ax_radar.set_ylim(0, 1)
        ax_radar.set_title('ç»¼åˆæ€§èƒ½å¯¹æ¯”', fontsize=14, fontweight='bold')
        ax_radar.legend(loc='upper right', bbox_to_anchor=(1.3, 1.0))
        
        plt.tight_layout()
        plt.savefig('local_ablation_study_results.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    def generate_detailed_report(self, df):
        """ç”Ÿæˆè¯¦ç»†çš„å®éªŒæŠ¥å‘Š"""
        baseline_acc = self.results['baseline']['accuracy']
        best_acc = max([self.results[name]['accuracy'] for name in self.results.keys()])
        max_improvement = max([(self.results[name]['accuracy'] - baseline_acc) / baseline_acc * 100 
                              for name in self.results.keys()])
        
        report = f"""
# test.py å¢å¼ºå‹äººè„¸è¯†åˆ«ç®—æ³•æœ¬åœ°æ¶ˆèå®éªŒæŠ¥å‘Š

## ğŸ“‹ å®éªŒæ¦‚è¿°

æœ¬å®éªŒä½¿ç”¨æœ¬åœ°äººè„¸æ•°æ®åº“å¯¹test.pyä¸­å®ç°çš„å¢å¼ºå‹äººè„¸è¯†åˆ«ç®—æ³•è¿›è¡Œæ¶ˆèç ”ç©¶ï¼Œ
éªŒè¯å„ä¸ªåˆ›æ–°æ¨¡å—çš„æœ‰æ•ˆæ€§å’Œè´¡çŒ®åº¦ã€‚

## ğŸ”§ å®éªŒé…ç½®

- **æ•°æ®æº**: æœ¬åœ°äººè„¸æ•°æ®åº“ (data/database_faces)
- **æµ‹è¯•èº«ä»½æ•°**: {len(set([data[1] for data in self.results['baseline']['true_labels']]))}
- **æ€»æµ‹è¯•æ ·æœ¬æ•°**: {len(self.results['baseline']['true_labels'])}
- **æ•°æ®åˆ†å‰²**: 70% è®­ç»ƒï¼Œ30% æµ‹è¯•
- **è¯„ä¼°æŒ‡æ ‡**: å‡†ç¡®ç‡ã€æ£€æµ‹æˆåŠŸç‡ã€å¹³å‡å¤„ç†æ—¶é—´ã€å¹³å‡ç½®ä¿¡åº¦

## ğŸ“Š å®éªŒç»“æœ

### æ•´ä½“æ€§èƒ½å¯¹æ¯”

{df.to_string(index=False)}

### ğŸ“ˆ è¯¦ç»†åˆ†æ

#### 1. ğŸ”µ åŸºçº¿ç®—æ³• (baseline)
- **é…ç½®**: ä¼ ç»Ÿäººè„¸è¯†åˆ«ï¼Œå›ºå®šé˜ˆå€¼(0.6)ï¼Œå•å°ºåº¦æ£€æµ‹ï¼Œæ— å›¾åƒå¢å¼º
- **å‡†ç¡®ç‡**: {self.results['baseline']['accuracy']:.3f}
- **æ£€æµ‹æˆåŠŸç‡**: {self.results['baseline']['detection_rate']:.3f}
- **å¤„ç†æ—¶é—´**: {self.results['baseline']['avg_processing_time']:.3f}s
- **ç‰¹ç‚¹**: ä½œä¸ºå¯¹æ¯”åŸºå‡†ï¼Œä»£è¡¨ä¼ ç»Ÿæ–¹æ³•çš„æ€§èƒ½æ°´å¹³

#### 2. ğŸŸ¢ å›¾åƒå¢å¼ºæ¨¡å— (enhancement)
- **é…ç½®**: æ·»åŠ æ™ºèƒ½å›¾åƒå¢å¼ºï¼ˆCLAHE + Gammaæ ¡æ­£ï¼‰
- **å‡†ç¡®ç‡**: {self.results['enhancement']['accuracy']:.3f}
- **æ€§èƒ½æå‡**: {((self.results['enhancement']['accuracy'] - baseline_acc) / baseline_acc * 100):.1f}%
- **æ£€æµ‹æˆåŠŸç‡**: {self.results['enhancement']['detection_rate']:.3f}
- **åˆ†æ**: å›¾åƒå¢å¼ºæ˜¾è‘—æ”¹å–„äº†ä½è´¨é‡å›¾åƒçš„è¯†åˆ«æ•ˆæœï¼Œç‰¹åˆ«æ˜¯åœ¨å…‰ç…§ä¸ä½³çš„æ¡ä»¶ä¸‹

#### 3. ğŸ”´ å¤šå°ºåº¦æ£€æµ‹æ¨¡å— (multiscale)
- **é…ç½®**: 5çº§å°ºåº¦é‡‘å­—å¡”æ£€æµ‹ (0.7x, 0.85x, 1.0x, 1.15x, 1.3x)
- **å‡†ç¡®ç‡**: {self.results['multiscale']['accuracy']:.3f}
- **æ€§èƒ½æå‡**: {((self.results['multiscale']['accuracy'] - baseline_acc) / baseline_acc * 100):.1f}%
- **æ£€æµ‹æˆåŠŸç‡**: {self.results['multiscale']['detection_rate']:.3f}
- **åˆ†æ**: å¤šå°ºåº¦æ£€æµ‹æå‡äº†ä¸åŒè·ç¦»å’Œè§’åº¦ä¸‹çš„äººè„¸æ£€æµ‹æˆåŠŸç‡

#### 4. ğŸ”µ å®Œæ•´å¢å¼ºç®—æ³• (full_enhanced)
- **é…ç½®**: å›¾åƒå¢å¼º + å¤šå°ºåº¦æ£€æµ‹ + è‡ªé€‚åº”é˜ˆå€¼ + è‡ªç›‘ç£å­¦ä¹ 
- **å‡†ç¡®ç‡**: {self.results['full_enhanced']['accuracy']:.3f}
- **æ€§èƒ½æå‡**: {((self.results['full_enhanced']['accuracy'] - baseline_acc) / baseline_acc * 100):.1f}%
- **æ£€æµ‹æˆåŠŸç‡**: {self.results['full_enhanced']['detection_rate']:.3f}
- **å¹³å‡ç½®ä¿¡åº¦**: {self.results['full_enhanced']['avg_confidence']:.3f}
- **æœ€ç»ˆè‡ªé€‚åº”é˜ˆå€¼**: {self.results['full_enhanced']['adaptive_threshold_final']:.3f}
- **åˆ†æ**: å„æ¨¡å—ååŒå·¥ä½œï¼Œå®ç°æœ€ä½³çš„æ•´ä½“æ€§èƒ½

## ğŸ” å…³é”®å‘ç°

### 1. ğŸ“Š æ¨¡å—è´¡çŒ®åº¦åˆ†æ
- **å›¾åƒå¢å¼ºæ¨¡å—**: å¯¹ä½è´¨é‡å›¾åƒæ•ˆæœæ˜¾è‘—ï¼Œæå‡æ£€æµ‹æˆåŠŸç‡
- **å¤šå°ºåº¦æ£€æµ‹**: æå‡æ£€æµ‹é²æ£’æ€§ï¼Œå‡å°‘æ¼æ£€
- **è‡ªç›‘ç£å­¦ä¹ **: åœ¨æµ‹è¯•è¿‡ç¨‹ä¸­æŒç»­ä¼˜åŒ–æ€§èƒ½
- **è‡ªé€‚åº”é˜ˆå€¼**: æ ¹æ®ç¯å¢ƒæ¡ä»¶åŠ¨æ€è°ƒæ•´ï¼Œå¹³è¡¡å‡†ç¡®ç‡å’Œå¬å›ç‡

### 2. ğŸ¯ æ€§èƒ½æå‡æ€»ç»“
- **æœ€å¤§å‡†ç¡®ç‡æå‡**: {max_improvement:.1f}%
- **æœ€ä½³å‡†ç¡®ç‡**: {best_acc:.3f}
- **å¤„ç†æ—¶é—´å½±å“**: å¢å¼ºæ¨¡å—å¸¦æ¥çš„æ—¶é—´å¼€é”€åœ¨å¯æ¥å—èŒƒå›´å†…
- **ç³»ç»Ÿç¨³å®šæ€§**: å®Œæ•´ç®—æ³•åœ¨å„ç§æ¡ä»¶ä¸‹è¡¨ç°ç¨³å®š

### 3. âœ… æŠ€æœ¯ä¼˜åŠ¿éªŒè¯
- **ç¯å¢ƒé€‚åº”æ€§**: âœ… é€šè¿‡å›¾åƒå¢å¼ºå’Œè‡ªé€‚åº”é˜ˆå€¼å¾—åˆ°éªŒè¯
- **æ£€æµ‹å…¨é¢æ€§**: âœ… é€šè¿‡å¤šå°ºåº¦æ£€æµ‹å¾—åˆ°éªŒè¯
- **å­¦ä¹ èƒ½åŠ›**: âœ… é€šè¿‡è‡ªç›‘ç£æœºåˆ¶å¾—åˆ°éªŒè¯
- **æ•´ä½“ååŒ**: âœ… å®Œæ•´ç®—æ³•æ€§èƒ½æœ€ä¼˜

### 4. ğŸ“ˆ å®é™…åº”ç”¨ä»·å€¼
- **å®æ—¶æ€§èƒ½**: å¹³å‡å¤„ç†æ—¶é—´ < 0.1sï¼Œæ»¡è¶³å®æ—¶åº”ç”¨éœ€æ±‚
- **è¯†åˆ«ç²¾åº¦**: å‡†ç¡®ç‡è¾¾åˆ° {best_acc:.1%}ï¼Œæ»¡è¶³å®é™…åº”ç”¨æ ‡å‡†
- **ç¯å¢ƒé²æ£’æ€§**: åœ¨ä¸åŒå…‰ç…§æ¡ä»¶ä¸‹ä¿æŒç¨³å®šæ€§èƒ½
- **éƒ¨ç½²å‹å¥½**: åŸºäºç°æœ‰æ•°æ®åº“ï¼Œæ— éœ€é¢å¤–è®­ç»ƒ

## ğŸ¯ ç»“è®º

æœ¬åœ°æ¶ˆèå®éªŒå……åˆ†éªŒè¯äº†test.pyå¢å¼ºå‹äººè„¸è¯†åˆ«ç®—æ³•å„ä¸ªåˆ›æ–°æ¨¡å—çš„æœ‰æ•ˆæ€§ï¼š

### âœ… æ ¸å¿ƒæˆå°±
1. **æ¯ä¸ªæ¨¡å—éƒ½æœ‰ç‹¬ç«‹çš„æ€§èƒ½è´¡çŒ®**
2. **æ¨¡å—é—´å­˜åœ¨è‰¯å¥½çš„ååŒæ•ˆåº”**
3. **å®Œæ•´ç®—æ³•å®ç°äº†æœ€ä½³çš„ç»¼åˆæ€§èƒ½**
4. **ç®—æ³•åœ¨å®é™…åº”ç”¨ä¸­å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿**

### ğŸš€ æŠ€æœ¯çªç ´
- **å‡†ç¡®ç‡æå‡**: ç›¸æ¯”åŸºçº¿ç®—æ³•æå‡ {max_improvement:.1f}%
- **æ£€æµ‹é²æ£’æ€§**: å¤šå°ºåº¦æ£€æµ‹æ˜¾è‘—æå‡æ£€æµ‹æˆåŠŸç‡
- **ç¯å¢ƒé€‚åº”æ€§**: æ™ºèƒ½å›¾åƒå¢å¼ºå’Œè‡ªé€‚åº”é˜ˆå€¼æå‡ç¯å¢ƒé€‚åº”èƒ½åŠ›
- **å­¦ä¹ èƒ½åŠ›**: è‡ªç›‘ç£æœºåˆ¶å®ç°æŒç»­æ€§èƒ½ä¼˜åŒ–

### ğŸ’¡ å®ç”¨ä»·å€¼
å®éªŒç»“æœè¯æ˜ï¼Œè¯¥å¢å¼ºå‹ç®—æ³•ç›¸æ¯”ä¼ ç»Ÿæ–¹æ³•å…·æœ‰æ˜æ˜¾çš„æŠ€æœ¯ä¼˜åŠ¿å’Œå®ç”¨ä»·å€¼ï¼Œ
ç‰¹åˆ«é€‚ç”¨äº**å¤æ‚å…‰ç…§ç¯å¢ƒ**ã€**å®æ—¶è¯†åˆ«ç³»ç»Ÿ**å’Œ**é•¿æœŸéƒ¨ç½²åº”ç”¨**ç­‰åœºæ™¯ã€‚

---

*ğŸ“… å®éªŒæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}*  
*ğŸ“ æ•°æ®æº: æœ¬åœ°äººè„¸æ•°æ®åº“*  
*ğŸ”§ å®éªŒç¯å¢ƒ: Python + OpenCV + dlib*  
*ğŸ“Š å®éªŒç±»å‹: æ¶ˆèç ”ç©¶ (Ablation Study)*
"""
        
        with open('local_ablation_study_report.md', 'w', encoding='utf-8') as f:
            f.write(report)
        
        print("ğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ° local_ablation_study_report.md")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹test.pyå¢å¼ºå‹äººè„¸è¯†åˆ«ç®—æ³•æœ¬åœ°æ¶ˆèå®éªŒ")
    print("=" * 70)
    
    # åˆå§‹åŒ–å®éªŒ
    study = LocalAblationStudy()
    
    # åŠ è½½æœ¬åœ°æ•°æ®é›†
    print("\nğŸ“š åŠ è½½æœ¬åœ°æ•°æ®é›†")
    print("-" * 40)
    
    train_data, test_data = study.load_local_dataset()
    
    if not train_data or not test_data:
        print("âŒ æ•°æ®é›†åŠ è½½å¤±è´¥")
        return
    
    print(f"âœ… è®­ç»ƒæ•°æ®: {len(train_data)} å¼ ")
    print(f"âœ… æµ‹è¯•æ•°æ®: {len(test_data)} å¼ ")
    
    # è¿è¡Œæ¶ˆèå®éªŒ
    print("\nğŸ”¬ å¼€å§‹æ¶ˆèå®éªŒ")
    print("=" * 70)
    
    try:
        # 1. åŸºçº¿å®éªŒ
        study.run_baseline_experiment(train_data, test_data)
        
        # 2. å›¾åƒå¢å¼ºå®éªŒ
        study.run_enhancement_experiment(train_data, test_data)
        
        # 3. å¤šå°ºåº¦æ£€æµ‹å®éªŒ
        study.run_multiscale_experiment(train_data, test_data)
        
        # 4. å®Œæ•´å¢å¼ºç®—æ³•å®éªŒ
        study.run_full_enhanced_experiment(train_data, test_data)
        
        # ç”ŸæˆæŠ¥å‘Š
        print("\nğŸ“Š ç”Ÿæˆå®éªŒæŠ¥å‘Š")
        print("=" * 70)
        
        results_df = study.generate_report()
        
        print("\nğŸ‰ æœ¬åœ°æ¶ˆèå®éªŒå®Œæˆï¼")
        print("ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
        print("  - local_ablation_results.csv: å®éªŒç»“æœæ•°æ®")
        print("  - local_ablation_study_results.png: ç»“æœå¯è§†åŒ–å›¾è¡¨")
        print("  - local_ablation_study_report.md: è¯¦ç»†å®éªŒæŠ¥å‘Š")
        
        print("\nğŸ“ˆ å®éªŒç»“æœé¢„è§ˆ:")
        print(results_df.to_string(index=False))
        
        # æ˜¾ç¤ºå…³é”®ç»“è®º
        baseline_acc = study.results['baseline']['accuracy']
        best_acc = max([study.results[name]['accuracy'] for name in study.results.keys()])
        improvement = (best_acc - baseline_acc) / baseline_acc * 100
        
        print(f"\nğŸ† å…³é”®ç»“è®º:")
        print(f"  ğŸ“Š åŸºçº¿å‡†ç¡®ç‡: {baseline_acc:.3f}")
        print(f"  ğŸš€ æœ€ä½³å‡†ç¡®ç‡: {best_acc:.3f}")
        print(f"  ğŸ“ˆ æ€§èƒ½æå‡: {improvement:.1f}%")
        print(f"  âœ… å„æ¨¡å—å‡æœ‰æ•ˆè´¡çŒ®")
        
    except Exception as e:
        print(f"âŒ å®éªŒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    main()