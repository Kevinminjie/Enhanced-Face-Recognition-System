#!/usr/bin/env python
# encoding: utf-8
'''
å¢å¼ºç‰ˆäººè„¸è¯†åˆ«ç³»ç»Ÿ - é›†æˆArcFaceå’Œæ³¨æ„åŠ›æœºåˆ¶
åŸºäºåŸæœ‰FaceRecognition.pyè¿›è¡Œæ”¹è¿›ï¼Œæå‡åœ¨å£ç½©ã€å¸½å­ã€æš—å…‰ç¯å¢ƒä¸‹çš„è¯†åˆ«å‡†ç¡®æ€§
'''

import csv
import glob
import os
import re
import shutil
import time
import warnings
from os import getcwd
import torch
import torch.nn as nn
import cv2
import dlib
import numpy as np
import pandas as pd
from PIL import Image, ImageDraw, ImageFont
from PyQt5 import QtCore, QtGui, QtWidgets
from PyQt5.QtGui import QMovie
from PyQt5.QtWidgets import QFileDialog, QTableWidgetItem, QAbstractItemView
from PyQt5.QtCore import Qt
import datetime
from PyQt5.QtCore import QThread, pyqtSignal
from facenet_pytorch import MTCNN

# å¯¼å…¥å¢å¼ºæ¨¡å—
try:
    import sys
    sys.path.append('..')
    from improved_face_recognition import ImprovedFaceRecognizer, ImprovedFacePreprocessor
    from face_recognition_integration import EnhancedFaceRecognition
    ENHANCED_MODE = True
    print("âœ“ å¢å¼ºæ¨¡å¼å·²å¯ç”¨ - ArcFace + æ³¨æ„åŠ›æœºåˆ¶")
except ImportError as e:
    print(f"âš  å¢å¼ºæ¨¡å—å¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨æ ‡å‡†æ¨¡å¼: {e}")
    ENHANCED_MODE = False

# å¿½ç•¥è­¦å‘Š
os.environ["TF_CPP_MIN_LOG_LEVEL"] = "3"
warnings.filterwarnings(action='ignore')

# åˆå§‹åŒ–MTCNN
mtcnn = MTCNN(keep_all=True, device='cuda' if torch.cuda.is_available() else 'cpu')

def augment_image(img):
    """æ•°æ®å¢å¼ºå‡½æ•°"""
    flip = cv2.flip(img, 1)  # é•œåƒ
    blur = cv2.GaussianBlur(img, (5, 5), 0)  # é«˜æ–¯æ¨¡ç³Š
    return [img, flip, blur]

class EnhancedModelLoader(QThread):
    """å¢å¼ºç‰ˆæ¨¡å‹åŠ è½½å™¨"""
    models_loaded = pyqtSignal(object, object, object, object)  # å¢åŠ å¢å¼ºè¯†åˆ«å™¨ä¿¡å·

    def run(self):
        try:
            # åˆå§‹åŒ– MTCNN æ£€æµ‹å™¨
            device = 'cuda' if torch.cuda.is_available() else 'cpu'
            mtcnn = MTCNN(keep_all=True, device=device)

            # dlib çš„äººè„¸å…³é”®ç‚¹é¢„æµ‹å™¨å’Œè¯†åˆ«æ¨¡å‹
            predictor = dlib.shape_predictor('../data/data_dlib/shape_predictor_68_face_landmarks.dat')
            reco_model = dlib.face_recognition_model_v1("../data/data_dlib/dlib_face_recognition_resnet_model_v1.dat")

            # åˆå§‹åŒ–å¢å¼ºè¯†åˆ«å™¨
            enhanced_recognizer = None
            if ENHANCED_MODE:
                try:
                    enhanced_recognizer = EnhancedFaceRecognition()
                    print("âœ“ å¢å¼ºè¯†åˆ«å™¨åˆå§‹åŒ–æˆåŠŸ")
                except Exception as e:
                    print(f"âš  å¢å¼ºè¯†åˆ«å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
                    enhanced_recognizer = None

            # å‘å°„æ¨¡å‹åŠ è½½å®Œæˆä¿¡å·
            self.models_loaded.emit(mtcnn, predictor, reco_model, enhanced_recognizer)
            
        except Exception as e:
            print(f"æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            self.models_loaded.emit(None, None, None, None)

from FaceRecognition_UI import Ui_MainWindow

class Face_MainWindow(Ui_MainWindow):
    """å¢å¼ºç‰ˆäººè„¸è¯†åˆ«ä¸»çª—å£"""
    
    def __init__(self, MainWindow):
        self.path_face_dir = "../data/database_faces/"
        self.fontC = ImageFont.truetype("./Font/platech.ttf", 14, 0)

        self.cap_video = None  # è§†é¢‘æµå¯¹è±¡
        self.path = getcwd()
        self.video_path = getcwd()

        # å®šæ—¶å™¨
        self.timer_camera = QtCore.QTimer()
        self.timer_camera_load = QtCore.QTimer()
        self.timer_video = QtCore.QTimer()
        self.flag_timer = ""

        self.CAM_NUM = 0
        self.cap = cv2.VideoCapture(self.CAM_NUM)
        self.cap_video = None

        self.current_image = None
        self.current_face = None

        # åˆå§‹åŒ–åŸºæœ¬å±æ€§
        self.count = 0
        self.count_face = 0
        self.col_row = []
        
        # ä¼ ç»Ÿdlibæ¨¡å‹
        self.detector = dlib.get_frontal_face_detector()
        self.predictor = None
        self.face_reco_model = None
        
        # å¢å¼ºè¯†åˆ«å™¨
        self.enhanced_recognizer = None
        self.use_enhanced_mode = ENHANCED_MODE
        
        # ç•Œé¢åˆå§‹åŒ–
        self.setupUi(MainWindow)
        self.retranslateUi(MainWindow)
        self.resetUi()
        self.slot_init()
        
        # äººè„¸æ•°æ®å­˜å‚¨
        self.face_feature_exist = []
        self.face_name_exist = []
        
        # è·Ÿè¸ªç›¸å…³å˜é‡
        self.last_centroid = []
        self.current_centroid = []
        self.last_face_name = []
        self.current_face_name = []
        self.last_face_cnt = 0
        self.current_face_cnt = 0
        self.current_face_position = []
        self.current_face_feature = []
        self.reclassify_cnt = 0
        self.reclassify_interval = 20
        self.last_current_distance = 0
        self.current_face_distance = []
        self.exist_flag = None
        
        # å¯åŠ¨æ¨¡å‹åŠ è½½
        self.model_loader = EnhancedModelLoader()
        self.model_loader.models_loaded.connect(self.on_models_loaded)
        self.model_loader.start()
        
        print("å¢å¼ºç‰ˆäººè„¸è¯†åˆ«ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    def on_models_loaded(self, mtcnn, predictor, reco_model, enhanced_recognizer):
        """æ¨¡å‹åŠ è½½å®Œæˆå›è°ƒ"""
        self.predictor = predictor
        self.face_reco_model = reco_model
        self.enhanced_recognizer = enhanced_recognizer
        
        if enhanced_recognizer is not None:
            self.use_enhanced_mode = True
            print("âœ“ å¢å¼ºæ¨¡å¼å·²æ¿€æ´»")
        else:
            self.use_enhanced_mode = False
            print("âš  ä½¿ç”¨æ ‡å‡†æ¨¡å¼")
    
    def enhanced_face_detection(self, image):
        """å¢å¼ºçš„äººè„¸æ£€æµ‹æ–¹æ³•"""
        if self.use_enhanced_mode and self.enhanced_recognizer:
            try:
                # ä½¿ç”¨å¢å¼ºæ£€æµ‹
                result = self.enhanced_recognizer.enhanced_face_detection(image)
                if result is not None:
                    return result
            except Exception as e:
                print(f"å¢å¼ºæ£€æµ‹å¤±è´¥ï¼Œå›é€€åˆ°æ ‡å‡†æ¨¡å¼: {e}")
        
        # å›é€€åˆ°æ ‡å‡†æ£€æµ‹
        return self.standard_face_detection(image)
    
    def standard_face_detection(self, image):
        """æ ‡å‡†äººè„¸æ£€æµ‹æ–¹æ³•"""
        try:
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            faces = self.detector(gray, 1)
            
            if len(faces) > 0:
                face = faces[0]
                x, y, w, h = face.left(), face.top(), face.width(), face.height()
                face_region = image[y:y+h, x:x+w]
                face_resized = cv2.resize(face_region, (112, 112))
                return face_resized
            
            return None
        except Exception as e:
            print(f"æ ‡å‡†æ£€æµ‹å¤±è´¥: {e}")
            return None
    
    def enhanced_face_recognition(self, image):
        """å¢å¼ºçš„äººè„¸è¯†åˆ«æ–¹æ³•"""
        if self.use_enhanced_mode and self.enhanced_recognizer:
            try:
                # ä½¿ç”¨å¢å¼ºè¯†åˆ«
                result = self.enhanced_recognizer.recognize_with_enhancement(image)
                return result['name'], result['confidence']
            except Exception as e:
                print(f"å¢å¼ºè¯†åˆ«å¤±è´¥ï¼Œå›é€€åˆ°æ ‡å‡†æ¨¡å¼: {e}")
        
        # å›é€€åˆ°æ ‡å‡†è¯†åˆ«
        return self.standard_face_recognition(image)
    
    def standard_face_recognition(self, image):
        """æ ‡å‡†äººè„¸è¯†åˆ«æ–¹æ³•"""
        try:
            if self.predictor is None or self.face_reco_model is None:
                return "æ¨¡å‹æœªåŠ è½½", 0.0
            
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            faces = self.detector(gray, 1)
            
            if len(faces) == 0:
                return "æœªæ£€æµ‹åˆ°äººè„¸", 0.0
            
            face = faces[0]
            landmarks = self.predictor(gray, face)
            face_descriptor = self.face_reco_model.compute_face_descriptor(gray, landmarks)
            face_descriptor = np.array(face_descriptor)
            
            # ä¸æ•°æ®åº“ä¸­çš„äººè„¸è¿›è¡Œæ¯”è¾ƒ
            if len(self.face_feature_exist) == 0:
                return "æ•°æ®åº“ä¸ºç©º", 0.0
            
            distances = []
            for feature in self.face_feature_exist:
                distance = np.linalg.norm(face_descriptor - feature)
                distances.append(distance)
            
            min_distance = min(distances)
            min_index = distances.index(min_distance)
            
            threshold = 0.6
            if min_distance < threshold:
                confidence = 1.0 - min_distance
                return self.face_name_exist[min_index], confidence
            else:
                return "æœªçŸ¥äººè„¸", 0.0
                
        except Exception as e:
            print(f"æ ‡å‡†è¯†åˆ«å¤±è´¥: {e}")
            return "è¯†åˆ«é”™è¯¯", 0.0
    
    def add_face_enhanced(self, name, image):
        """å¢å¼ºçš„äººè„¸æ·»åŠ æ–¹æ³•"""
        if self.use_enhanced_mode and self.enhanced_recognizer:
            try:
                # ä½¿ç”¨å¢å¼ºæ–¹æ³•æ·»åŠ äººè„¸
                success = self.enhanced_recognizer.add_face_with_enhancement(name, image)
                if success:
                    print(f"âœ“ ä½¿ç”¨å¢å¼ºæ¨¡å¼æˆåŠŸæ·»åŠ  {name}")
                    return True
            except Exception as e:
                print(f"å¢å¼ºæ·»åŠ å¤±è´¥ï¼Œå›é€€åˆ°æ ‡å‡†æ¨¡å¼: {e}")
        
        # å›é€€åˆ°æ ‡å‡†æ–¹æ³•
        return self.add_face_standard(name, image)
    
    def add_face_standard(self, name, image):
        """æ ‡å‡†äººè„¸æ·»åŠ æ–¹æ³•"""
        try:
            if self.predictor is None or self.face_reco_model is None:
                print("æ¨¡å‹æœªåŠ è½½")
                return False
            
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            faces = self.detector(gray, 1)
            
            if len(faces) == 0:
                print("æœªæ£€æµ‹åˆ°äººè„¸")
                return False
            
            face = faces[0]
            landmarks = self.predictor(gray, face)
            face_descriptor = self.face_reco_model.compute_face_descriptor(gray, landmarks)
            face_descriptor = np.array(face_descriptor)
            
            # æ·»åŠ åˆ°æ•°æ®åº“
            self.face_feature_exist.append(face_descriptor)
            self.face_name_exist.append(name)
            
            print(f"âœ“ ä½¿ç”¨æ ‡å‡†æ¨¡å¼æˆåŠŸæ·»åŠ  {name}")
            return True
            
        except Exception as e:
            print(f"æ ‡å‡†æ·»åŠ å¤±è´¥: {e}")
            return False
    
    def process_video_frame_enhanced(self, frame):
        """å¢å¼ºçš„è§†é¢‘å¸§å¤„ç†"""
        if self.use_enhanced_mode and self.enhanced_recognizer:
            try:
                # ä½¿ç”¨å¢å¼ºå¤„ç†
                processed_frame, name, confidence = self.enhanced_recognizer.process_video_frame(frame)
                return processed_frame, name, confidence
            except Exception as e:
                print(f"å¢å¼ºå¤„ç†å¤±è´¥ï¼Œå›é€€åˆ°æ ‡å‡†æ¨¡å¼: {e}")
        
        # å›é€€åˆ°æ ‡å‡†å¤„ç†
        return self.process_video_frame_standard(frame)
    
    def process_video_frame_standard(self, frame):
        """æ ‡å‡†è§†é¢‘å¸§å¤„ç†"""
        try:
            name, confidence = self.enhanced_face_recognition(frame)
            
            # åœ¨å¸§ä¸Šç»˜åˆ¶ç»“æœ
            annotated_frame = self.draw_recognition_result(frame, name, confidence)
            
            return annotated_frame, name, confidence
            
        except Exception as e:
            print(f"æ ‡å‡†å¤„ç†å¤±è´¥: {e}")
            return frame, "å¤„ç†é”™è¯¯", 0.0
    
    def draw_recognition_result(self, image, name, confidence):
        """åœ¨å›¾åƒä¸Šç»˜åˆ¶è¯†åˆ«ç»“æœ"""
        try:
            annotated = image.copy()
            gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
            faces = self.detector(gray, 1)
            
            for face in faces:
                x, y, w, h = face.left(), face.top(), face.width(), face.height()
                
                # ç»˜åˆ¶äººè„¸æ¡†
                color = (0, 255, 0) if confidence > 0.6 else (0, 0, 255)
                cv2.rectangle(annotated, (x, y), (x+w, y+h), color, 2)
                
                # ç»˜åˆ¶è¯†åˆ«ç»“æœæ–‡æœ¬
                text = f"{name}: {confidence:.2f}"
                cv2.putText(annotated, text, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, color, 2)
            
            return annotated
            
        except Exception as e:
            print(f"ç»˜åˆ¶ç»“æœå¤±è´¥: {e}")
            return image
    
    # ä»¥ä¸‹æ˜¯åŸæœ‰æ–¹æ³•çš„å¢å¼ºç‰ˆæœ¬
    def resetUi(self):
        """é‡ç½®UIç•Œé¢"""
        # è®¾ç½®è¡¨æ ¼å½¢å¼
        self.tableWidget_rec.horizontalHeader().setVisible(True)
        self.tableWidget_mana.horizontalHeader().setVisible(True)
        self.tableWidget_rec.setColumnWidth(0, 80)
        self.tableWidget_rec.setColumnWidth(1, 200)
        self.tableWidget_rec.setColumnWidth(2, 150)
        self.tableWidget_rec.setColumnWidth(3, 200)
        self.tableWidget_rec.setColumnWidth(4, 120)

        self.tableWidget_mana.setColumnWidth(0, 80)
        self.tableWidget_mana.setColumnWidth(1, 350)
        self.tableWidget_mana.setColumnWidth(2, 150)
        self.tableWidget_mana.setColumnWidth(3, 150)
        self.tableWidget_mana.setSelectionBehavior(QAbstractItemView.SelectRows)
        self.tabWidget.setCurrentIndex(0)
        self.tabWidget.setTabVisible(0, True)
        self.tabWidget.setTabVisible(1, False)
        self.tabWidget.setTabVisible(2, False)

        # è®¾ç½®åˆå§‹æŒ‰é’®çŠ¶æ€
        self.toolButton_get_pic.setEnabled(False)
        self.toolButton_load_pic.setEnabled(False)
        self.toolButton_file_2.setEnabled(False)
        self.toolButton_camera_load.setEnabled(False)

        # è®¾ç½®ç•Œé¢åŠ¨ç”»
        self.gif_movie()
        
        # æ˜¾ç¤ºå¢å¼ºæ¨¡å¼çŠ¶æ€
        if self.use_enhanced_mode:
            print("ğŸš€ ç•Œé¢å·²å¯ç”¨å¢å¼ºæ¨¡å¼")
    
    def gif_movie(self):
        """è®¾ç½®ç•Œé¢åŠ¨ç”»"""
        gif = QMovie(':/newPrefix/images_test/face_rec.gif')
        self.label_display.setMovie(gif)
        self.label_display.setScaledContents(True)
        gif.start()
    
    def slot_init(self):
        """åˆå§‹åŒ–æ§½å‡½æ•°è¿æ¥"""
        try:
            # ç•Œé¢åˆ‡æ¢æŒ‰é’®
            self.toolButton_run_load.clicked.connect(self.change_size_load)
            self.toolButton_run_rec.clicked.connect(self.change_size_rec)
            self.toolButton_run_manage.clicked.connect(self.change_size_mana)
            
            # å½•å…¥ç•Œé¢æŒ‰é’®
            self.toolButton_new_folder.clicked.connect(self.new_face_doing)
            self.toolButton_file_2.clicked.connect(self.choose_file)
            self.toolButton_get_pic.clicked.connect(self.get_img_doing)
            self.toolButton_load_pic.clicked.connect(self.load_img_doing)
            self.toolButton_camera_load.clicked.connect(self.button_open_camera_load)
            self.timer_camera_load.timeout.connect(self.show_camera_load)
            
            # è¯†åˆ«ç•Œé¢æŒ‰é’®
            self.toolButton_file.clicked.connect(self.choose_rec_img)
            self.toolButton_runing.clicked.connect(self.run_rec)
            self.toolButton_camera.clicked.connect(self.button_open_camera_click)
            self.toolButton_video.clicked.connect(self.button_open_video_click)
            
            # å®šæ—¶å™¨è¿æ¥ - æ ¹æ®æ¨¡å¼é€‰æ‹©å¤„ç†å‡½æ•°
            if self.use_enhanced_mode:
                self.timer_camera.timeout.connect(self.show_camera_enhanced)
                self.timer_video.timeout.connect(self.show_video_enhanced)
            else:
                self.timer_camera.timeout.connect(self.show_camera)
                self.timer_video.timeout.connect(self.show_video)
            
            # ç®¡ç†ç•Œé¢æŒ‰é’®
            self.toolButton_mana_update.clicked.connect(self.do_update_face)
            self.tableWidget_mana.cellPressed.connect(self.table_review)
            self.toolButton_mana_delete.clicked.connect(self.delete_doing)
            
            print("âœ“ ä¿¡å·æ§½è¿æ¥å®Œæˆ")
        except Exception as e:
            print(f"ä¿¡å·æ§½è¿æ¥å¼‚å¸¸: {str(e)}")
    
    def show_camera_enhanced(self):
        """å¢å¼ºçš„æ‘„åƒå¤´æ˜¾ç¤ºæ–¹æ³•"""
        try:
            flag, image = self.cap.read()
            if not flag:
                return
            
            # ä½¿ç”¨å¢å¼ºå¤„ç†
            processed_frame, name, confidence = self.process_video_frame_enhanced(image)
            
            # æ›´æ–°UIæ˜¾ç¤º
            self.update_ui_with_result(processed_frame, name, confidence)
            
        except Exception as e:
            print(f"æ‘„åƒå¤´æ˜¾ç¤ºå¤±è´¥: {e}")
    
    def show_video_enhanced(self):
        """å¢å¼ºçš„è§†é¢‘æ˜¾ç¤ºæ–¹æ³•"""
        try:
            if self.cap_video is None:
                return
                
            flag, image = self.cap_video.read()
            if not flag:
                return
            
            # ä½¿ç”¨å¢å¼ºå¤„ç†
            processed_frame, name, confidence = self.process_video_frame_enhanced(image)
            
            # æ›´æ–°UIæ˜¾ç¤º
            self.update_ui_with_result(processed_frame, name, confidence)
            
        except Exception as e:
            print(f"è§†é¢‘æ˜¾ç¤ºå¤±è´¥: {e}")
    
    def update_ui_with_result(self, frame, name, confidence):
        """æ›´æ–°UIæ˜¾ç¤ºç»“æœ"""
        try:
            # æ˜¾ç¤ºå¤„ç†åçš„å¸§
            show = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            showImage = QtGui.QImage(show.data, show.shape[1], show.shape[0], QtGui.QImage.Format_RGB888)
            pixmap = QtGui.QPixmap.fromImage(showImage)
            self.label_display.setPixmap(pixmap)
            self.label_display.setScaledContents(True)
            
            # æ›´æ–°è¯†åˆ«ç»“æœæ ‡ç­¾
            self.label_plate_result.setText(name)
            self.label_score_dis.setText(f"{confidence:.3f}")
            
            # å¦‚æœè¯†åˆ«æˆåŠŸï¼Œæ›´æ–°è¡¨æ ¼
            if confidence > 0.6:
                time_now = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                self.change_table("å®æ—¶è¯†åˆ«", name, time_now, 1.0 - confidence)
            
            QtWidgets.QApplication.processEvents()
            
        except Exception as e:
            print(f"UIæ›´æ–°å¤±è´¥: {e}")
    
    # ä¿ç•™åŸæœ‰çš„å…¶ä»–æ–¹æ³•ï¼Œä½†æ·»åŠ å¢å¼ºåŠŸèƒ½è°ƒç”¨
    def cv_imread(self, file_path):
        """è¯»å–åŒ…å«ä¸­æ–‡è·¯å¾„çš„å›¾åƒ"""
        cv_img = cv2.imdecode(np.fromfile(file_path, dtype=np.uint8), -1)
        return cv_img
    
    def save_enhanced_database(self):
        """ä¿å­˜å¢å¼ºæ•°æ®åº“"""
        if self.use_enhanced_mode and self.enhanced_recognizer:
            try:
                filepath = "../data/enhanced_face_database.pkl"
                success = self.enhanced_recognizer.save_face_database(filepath)
                if success:
                    print("âœ“ å¢å¼ºæ•°æ®åº“å·²ä¿å­˜")
                    return True
            except Exception as e:
                print(f"ä¿å­˜å¢å¼ºæ•°æ®åº“å¤±è´¥: {e}")
        return False
    
    def load_enhanced_database(self):
        """åŠ è½½å¢å¼ºæ•°æ®åº“"""
        if self.use_enhanced_mode and self.enhanced_recognizer:
            try:
                filepath = "../data/enhanced_face_database.pkl"
                success = self.enhanced_recognizer.load_face_database(filepath)
                if success:
                    print("âœ“ å¢å¼ºæ•°æ®åº“å·²åŠ è½½")
                    return True
            except Exception as e:
                print(f"åŠ è½½å¢å¼ºæ•°æ®åº“å¤±è´¥: {e}")
        return False
    
    # ä»åŸå§‹ä»£ç å¤åˆ¶çš„å®Œæ•´æ–¹æ³•å®ç°
    def choose_rec_img(self):
        """é€‰æ‹©è¯†åˆ«å›¾åƒ"""
        fileName_choose, filetype = QFileDialog.getOpenFileName(self.centralwidget,
                                                                "é€‰å–å›¾ç‰‡æ–‡ä»¶",
                                                                "../test_img/",
                                                                "å›¾ç‰‡(*.jpg;*.png;*.jpeg)")
        if fileName_choose != '':
            self.path = fileName_choose
            self.textEdit_file.setText(fileName_choose + 'æ–‡ä»¶å·²é€‰ä¸­')
            self.textEdit_file.setStyleSheet("background-color: transparent;\n"
                                           "border-color: rgb(0, 170, 255);\n"
                                           "color: rgb(0, 170, 255);\n"
                                           "font: regular 12pt \"åä¸ºä»¿å®‹\";")
            # æ˜¾ç¤ºé€‰æ‹©çš„å›¾ç‰‡
            img = self.cv_imread(fileName_choose)
            if img is not None:
                show = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)
                showImage = QtGui.QImage(show.data, show.shape[1], show.shape[0], QtGui.QImage.Format_RGB888)
                pixmap = QtGui.QPixmap.fromImage(showImage)
                self.label_display.setPixmap(pixmap)
                self.label_display.setScaledContents(True)
        else:
            self.textEdit_file.setText('å›¾ç‰‡æ–‡ä»¶æœªé€‰ä¸­')
            self.textEdit_file.setStyleSheet("background-color: transparent;\n"
                                           "border-color: rgb(0, 170, 255);\n"
                                           "color: rgb(0, 170, 255);\n"
                                           "font: regular 12pt \"åä¸ºä»¿å®‹\";")
    
    def run_rec(self):
        """è¿è¡Œè¯†åˆ«"""
        if self.path != '':
            self.do_choose_file()
        else:
            QtWidgets.QMessageBox.warning(self.centralwidget, "è­¦å‘Š", "è¯·å…ˆé€‰æ‹©å›¾ç‰‡æ–‡ä»¶ï¼")
    
    def do_choose_file(self):
        """é€‰æ‹©å›¾ç‰‡è¯†åˆ«æ—¶è¿è¡Œå‡½æ•°"""
        if self.path != '':
            self.label_display.clear()
            self.label_pic_newface.clear()
            QtWidgets.QApplication.processEvents()
            
            # è·å–å·²å­˜åœ¨äººè„¸çš„ç‰¹å¾
            exist_flag = self.get_face_database()
            img_rd = self.cv_imread(self.path)
            
            if img_rd is None:
                QtWidgets.QMessageBox.warning(self.centralwidget, "é”™è¯¯", "æ— æ³•è¯»å–å›¾ç‰‡æ–‡ä»¶ï¼")
                return
            
            # ä½¿ç”¨å¢å¼ºè¯†åˆ«æˆ–æ ‡å‡†è¯†åˆ«
            if self.use_enhanced_mode and self.enhanced_recognizer:
                try:
                    result = self.enhanced_recognizer.recognize_face(img_rd)
                    if result:
                        name, confidence = result
                        self.label_plate_result.setText(name)
                        self.label_score_dis.setText(f"{confidence:.3f}")
                        
                        # æ˜¾ç¤ºå¤„ç†åçš„å›¾ç‰‡
                        processed_img = self.enhanced_recognizer.preprocessor.enhance_low_light(img_rd)
                        show = cv2.cvtColor(processed_img, cv2.COLOR_BGR2RGB)
                        showImage = QtGui.QImage(show.data, show.shape[1], show.shape[0], QtGui.QImage.Format_RGB888)
                        pixmap = QtGui.QPixmap.fromImage(showImage)
                        self.label_display.setPixmap(pixmap)
                        self.label_display.setScaledContents(True)
                        
                        # è®°å½•è¯†åˆ«ç»“æœ
                        time_now = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                        self.change_table("å›¾ç‰‡è¯†åˆ«", name, time_now, 1.0 - confidence)
                        return
                except Exception as e:
                    print(f"å¢å¼ºè¯†åˆ«å¤±è´¥ï¼Œä½¿ç”¨æ ‡å‡†è¯†åˆ«: {e}")
            
            # æ ‡å‡†è¯†åˆ«æµç¨‹
            image = img_rd.copy()
            faces = self.detector(image, 0)
            
            if len(faces) > 0:
                self.label_score_num.setText(str(len(faces)))
                
                for k, d in enumerate(faces):
                    # æå–äººè„¸ç‰¹å¾
                    shape = self.predictor(img_rd, faces[k])
                    face_feature = self.face_reco_model.compute_face_descriptor(img_rd, shape)
                    
                    # ä¸æ•°æ®åº“ä¸­çš„äººè„¸è¿›è¡Œæ¯”è¾ƒ
                    min_dis = 999999999
                    similar_person_num = -1
                    
                    for i in range(len(self.face_feature_exist)):
                        if str(self.face_feature_exist[i][0]) != '0.0':
                            e_distance_tmp = self.euclidean_distance(face_feature, self.face_feature_exist[i])
                            if e_distance_tmp < min_dis:
                                min_dis = e_distance_tmp
                                similar_person_num = i
                    
                    # æ˜¾ç¤ºè¯†åˆ«ç»“æœ
                    if min_dis < 0.4 and similar_person_num >= 0:
                        name = self.face_name_exist[similar_person_num]
                    else:
                        name = "æœªçŸ¥äººè„¸"
                    
                    self.label_plate_result.setText(name)
                    self.label_score_dis.setText(str(round(min_dis, 3)))
                    
                    # åœ¨å›¾ç‰‡ä¸Šç»˜åˆ¶äººè„¸æ¡†
                    rect = (d.left(), d.top(), d.right(), d.bottom())
                    image = self.drawRectBox(image, rect, name)
                    
                    # è®°å½•è¯†åˆ«ç»“æœ
                    time_now = datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                    self.change_table("å›¾ç‰‡è¯†åˆ«", name, time_now, min_dis)
                
                # æ˜¾ç¤ºå¤„ç†åçš„å›¾ç‰‡
                show = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                showImage = QtGui.QImage(show.data, show.shape[1], show.shape[0], QtGui.QImage.Format_RGB888)
                pixmap = QtGui.QPixmap.fromImage(showImage)
                self.label_display.setPixmap(pixmap)
                self.label_display.setScaledContents(True)
            else:
                self.label_plate_result.setText("æœªæ£€æµ‹åˆ°äººè„¸")
                self.label_score_dis.setText("0")
    
    def button_open_camera_click(self):
        """æ‰“å¼€æ‘„åƒå¤´"""
        if self.timer_camera_load.isActive():
            self.timer_camera_load.stop()
        if self.timer_video.isActive():
            self.timer_video.stop()
        if self.cap:
            self.cap.release()
        if self.cap_video:
            self.cap_video.release()
        
        self.label_display.clear()
        self.gif_movie()
        self.label_pic_newface.clear()
        self.ini_value()
        
        if not self.timer_camera.isActive():
            flag = self.cap.open(self.CAM_NUM)
            if not flag:
                QtWidgets.QMessageBox.warning(self.centralwidget, "è­¦å‘Š",
                                              "è¯·æ£€æµ‹ç›¸æœºä¸ç”µè„‘æ˜¯å¦è¿æ¥æ­£ç¡®ï¼",
                                              buttons=QtWidgets.QMessageBox.Ok,
                                              defaultButton=QtWidgets.QMessageBox.Ok)
                self.flag_timer = ""
            else:
                self.textEdit_camera.setText("ç›¸æœºå‡†å¤‡å°±ç»ª")
                self.textEdit_camera.setStyleSheet("background-color: transparent;\n"
                                                   "border-color: rgb(0, 170, 255);\n"
                                                   "color: rgb(0, 170, 255);\n"
                                                   "font: regular 12pt \"åä¸ºä»¿å®‹\";")
                self.flag_timer = "camera"
                self.get_face_database()
                self.timer_camera.start(30)
        else:
            self.flag_timer = ""
            self.timer_camera.stop()
            if self.cap:
                self.cap.release()
            self.label_display.clear()
            self.gif_movie()
            self.textEdit_camera.setText('å®æ—¶æ‘„åƒå·²å…³é—­')
            self.textEdit_camera.setStyleSheet("background-color: transparent;\n"
                                               "border-color: rgb(0, 170, 255);\n"
                                               "color: rgb(0, 170, 255);\n"
                                               "font: regular 12pt \"åä¸ºä»¿å®‹\";")
    
    def button_open_video_click(self):
        """æ‰“å¼€è§†é¢‘"""
        if self.timer_camera.isActive():
            self.timer_camera.stop()
        if self.cap:
            self.cap.release()
        if self.cap_video:
            self.cap_video.release()
        
        self.label_display.clear()
        self.gif_movie()
        self.label_pic_newface.clear()
        self.ini_value()
        
        if not self.timer_video.isActive():
            fileName_choose, filetype = QFileDialog.getOpenFileName(self.centralwidget, "é€‰å–è§†é¢‘æ–‡ä»¶",
                                                                    "../test_img/",
                                                                    "è§†é¢‘(*.mp4;*.avi)")
            if fileName_choose != '':
                self.flag_timer = "video"
                self.textEdit_video.setText(fileName_choose + 'æ–‡ä»¶å·²é€‰ä¸­')
                self.textEdit_video.setStyleSheet("background-color: transparent;\n"
                                                  "border-color: rgb(0, 170, 255);\n"
                                                  "color: rgb(0, 170, 255);\n"
                                                  "font: regular 12pt \"åä¸ºä»¿å®‹\";")
                try:
                    self.cap_video = cv2.VideoCapture(fileName_choose)
                    self.get_face_database()
                    self.timer_video.start(30)
                except Exception as e:
                    print(f"è§†é¢‘æ‰“å¼€å¤±è´¥: {e}")
            else:
                self.textEdit_video.setText('è§†é¢‘æ–‡ä»¶æœªé€‰ä¸­')
        else:
            self.flag_timer = ""
            self.timer_video.stop()
            if self.cap_video:
                self.cap_video.release()
            self.label_display.clear()
            self.gif_movie()
            self.textEdit_video.setText('å®æ—¶è§†é¢‘å·²å…³é—­')
    
    # æ·»åŠ å…¶ä»–å¿…è¦çš„è¾…åŠ©æ–¹æ³•
    def ini_value(self):
        """åˆå§‹åŒ–æ•°å€¼"""
        self.label_plate_result.setText("æœªçŸ¥äººè„¸")
        self.label_score_fps.setText("0")
        self.label_score_num.setText("0")
        self.label_score_dis.setText("0")
    
    def gif_movie(self):
        """æ˜¾ç¤ºGIFåŠ¨ç”»"""
        try:
            self.movie = QtGui.QMovie(":/newPrefix/images_test/face_rec.gif")
            self.label_display.setMovie(self.movie)
            self.movie.start()
        except:
            pass
    
    def drawRectBox(self, image, rect, addText):
        """ç»˜åˆ¶äººè„¸æ¡†"""
        cv2.rectangle(image, (rect[0], rect[1]), (rect[2], rect[3]), (0, 255, 0), 2)
        cv2.putText(image, addText, (rect[0], rect[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 0), 2)
        return image
    
    def euclidean_distance(self, feature_1, feature_2):
        """è®¡ç®—æ¬§å¼è·ç¦»"""
        feature_1 = np.array(feature_1)
        feature_2 = np.array(feature_2)
        dist = np.sqrt(np.sum(np.square(feature_1 - feature_2)))
        return dist
     
    # æ·»åŠ ç•Œé¢åˆ‡æ¢å’Œäººè„¸å½•å…¥ç›¸å…³æ–¹æ³•
    def change_size_load(self):
         """åˆ‡æ¢åˆ°å½•å…¥ç•Œé¢"""
         self.toolButton_run_load.setGeometry(26, 218, 280, 70)
         self.toolButton_run_rec.setGeometry(66, 324, 199, 49)
         self.toolButton_run_manage.setGeometry(66, 414, 199, 49)
         self.tabWidget.setCurrentIndex(1)
         self.tabWidget.setTabVisible(0, False)
         self.tabWidget.setTabVisible(1, True)
         self.tabWidget.setTabVisible(2, False)
 
         self.flag_timer = ""
         if self.timer_camera.isActive():
             self.timer_camera.stop()
         if self.timer_video.isActive():
             self.timer_video.stop()
         if self.cap:
             self.cap.release()
         if self.cap_video:
             self.cap_video.release()
 
         QtWidgets.QApplication.processEvents()
         self.label_display.clear()
         self.gif_movie()
         self.label_pic_newface.clear()
         self.label_pic_org.clear()
     
    def change_size_rec(self):
        """åˆ‡æ¢åˆ°è¯†åˆ«ç•Œé¢"""
        self.toolButton_run_load.setGeometry(66, 236, 199, 49)
        self.toolButton_run_rec.setGeometry(26, 312, 280, 70)
        self.toolButton_run_manage.setGeometry(66, 414, 199, 49)
        self.tabWidget.setCurrentIndex(0)
        self.tabWidget.setTabVisible(0, True)
        self.tabWidget.setTabVisible(1, False)
        self.tabWidget.setTabVisible(2, False)

        if self.timer_camera_load.isActive():
            self.timer_camera_load.stop()
        if self.cap:
            self.cap.release()

        QtWidgets.QApplication.processEvents()
        self.label_display.clear()
        self.gif_movie()
        self.label_pic_newface.clear()

        self.lineEdit_face_name.setText("è¯·åœ¨æ­¤è¾“å…¥äººè„¸å")
        self.label_new_res.setText("ç­‰å¾…æ–°å»ºäººè„¸æ–‡ä»¶å¤¹")
        self.label_loadface.setText("ç­‰å¾…ç‚¹å‡»ä»¥å½•å…¥äººè„¸")
        self.toolButton_get_pic.setEnabled(False)
        self.toolButton_load_pic.setEnabled(False)
    
    def change_size_mana(self):
        """åˆ‡æ¢åˆ°ç®¡ç†ç•Œé¢"""
        self.toolButton_run_load.setGeometry(66, 236, 199, 49)
        self.toolButton_run_rec.setGeometry(66, 324, 199, 49)
        self.toolButton_run_manage.setGeometry(26, 410, 280, 70)
        self.tabWidget.setCurrentIndex(2)
        self.tabWidget.setTabVisible(0, False)
        self.tabWidget.setTabVisible(1, False)
        self.tabWidget.setTabVisible(2, True)
        self.update_face()
     
    def new_face_doing(self):
        """æ–°å»ºäººè„¸æ–‡ä»¶å¤¹"""
        try:
            self.toolButton_get_pic.setEnabled(False)
            self.toolButton_load_pic.setEnabled(False)
            self.label_display.clear()
            self.label_pic_newface.clear()
            self.current_face = None
            
            face_name = self.lineEdit_face_name.text()
            if face_name != "è¯·åœ¨æ­¤è¾“å…¥äººè„¸å" and face_name != "":
                face_dir_path = self.path_face_dir + face_name
                if not os.path.isdir(face_dir_path):
                    try:
                        os.makedirs(face_dir_path, exist_ok=True)
                        self.label_new_res.setText("è¾“å…¥çš„æ˜¯æ–°äººåï¼Œå·²æ–°å»ºäººè„¸æ–‡ä»¶å¤¹ï¼")
                        self.label_loadface.setText("æ–°å»ºå®Œæˆï¼Œè¯·ç‚¹å‡»å·¦ä¾§æŒ‰é’®é€‰æ‹©å›¾ç‰‡æˆ–æ‘„åƒå½•å…¥ï¼")
                    except Exception as e:
                        self.label_new_res.setText(f"åˆ›å»ºæ–‡ä»¶å¤¹å¤±è´¥ï¼š{str(e)}")
                        self.label_loadface.setText("æ–‡ä»¶å¤¹åˆ›å»ºå¤±è´¥ï¼Œè¯·æ£€æŸ¥æƒé™æˆ–è·¯å¾„ï¼")
                        return
                else:
                    self.label_new_res.setText("è¯¥äººåå·²å­˜åœ¨ï¼Œç»§ç»­å½•å…¥å°†å†™å…¥æ›´å¤šç…§ç‰‡ï¼")
                    self.label_loadface.setText("æ–‡ä»¶å¤¹å­˜åœ¨ï¼Œè¯·ç‚¹å‡»å·¦ä¾§æŒ‰é’®é€‰æ‹©å›¾ç‰‡æˆ–æ‘„åƒå–å›¾ï¼")
                    
                self.toolButton_file_2.setEnabled(True)
                self.toolButton_camera_load.setEnabled(True)
            else:
                self.label_new_res.setText("è¯·åœ¨å·¦ä¸‹è§’æ–‡æœ¬æ¡†ä¸­è¾“å…¥äººè„¸åå­—ï¼")
                self.label_loadface.setText("è¯·å…ˆè¾“å…¥è¦å½•å…¥çš„äººè„¸åå­—ï¼")
        except Exception as e:
            self.label_new_res.setText(f"å¤„ç†äººè„¸åç§°æ—¶å‘ç”Ÿå¼‚å¸¸ï¼š{str(e)}")
            print(f"new_face_doingå¼‚å¸¸: {str(e)}")
     
    def choose_file(self):
        """é€‰æ‹©æ–‡ä»¶"""
        try:
            fileName_choose, filetype = QFileDialog.getOpenFileName(
                self.centralwidget, "é€‰å–å›¾ç‰‡æ–‡ä»¶",
                self.path, "å›¾ç‰‡(*.jpg;*.jpeg;*.png)")
            self.path = fileName_choose
            
            if self.path != '':
                try:
                    img_rd = self.cv_imread(self.path)
                    if img_rd is None:
                        self.label_loadface.setText("æ— æ³•è¯»å–é€‰æ‹©çš„å›¾ç‰‡æ–‡ä»¶ï¼")
                        return
                    
                    image = img_rd.copy()
                    face_name = self.lineEdit_face_name.text()
                    faces = self.detector(image, 0)
                    
                    if len(faces) != 0:
                        for k, d in enumerate(faces):
                            try:
                                height = (d.bottom() - d.top())
                                width = (d.right() - d.left())
                                hh = int(height / 2)
                                ww = int(width / 2)
                                rect = (d.left() - ww, d.top() - hh, d.right() + ww, d.bottom() + hh)
                                image = self.drawRectBox(image, rect, "æœªçŸ¥")

                                y2 = d.right() + ww
                                x2 = d.bottom() + hh
                                y1 = d.left() - ww
                                x1 = d.top() - hh
                                
                                if y2 > img_rd.shape[1]: y2 = img_rd.shape[1]
                                elif x2 > img_rd.shape[0]: x2 = img_rd.shape[0]
                                elif y1 < 0: y1 = 0
                                elif x1 < 0: x1 = 0

                                crop_face = img_rd[x1: x2, y1: y2]
                                if crop_face.size > 0:
                                    self.current_face = crop_face
                                    self.disp_face(crop_face)

                                    if self.current_face.any() and face_name != "è¯·åœ¨æ­¤è¾“å…¥äººè„¸å" and face_name != "":
                                        self.label_loadface.setText("æ£€æµ‹åˆ°äººè„¸åŒºåŸŸï¼Œå¯ç‚¹å‡»å–å›¾æŒ‰é’®ä»¥ä¿å­˜ï¼")
                                        self.toolButton_get_pic.setEnabled(True)
                                else:
                                    self.label_loadface.setText("äººè„¸åŒºåŸŸæ— æ•ˆï¼Œè¯·é‡æ–°é€‰æ‹©å›¾ç‰‡ï¼")
                            except Exception as e:
                                print(f"å¤„ç†äººè„¸åŒºåŸŸæ—¶å‘ç”Ÿå¼‚å¸¸: {str(e)}")
                                continue

                        self.disp_img(image)
                    else:
                        self.label_loadface.setText("æœªæ£€æµ‹åˆ°äººè„¸ï¼Œè¯·é€‰æ‹©åŒ…å«äººè„¸çš„å›¾ç‰‡ï¼")
                        self.disp_img(image)
                except Exception as e:
                    self.label_loadface.setText(f"å¤„ç†å›¾ç‰‡æ—¶å‘ç”Ÿå¼‚å¸¸ï¼š{str(e)}")
            else:
                self.label_loadface.setText("æœªé€‰æ‹©ä»»ä½•æ–‡ä»¶ï¼")
        except Exception as e:
            self.label_loadface.setText(f"é€‰æ‹©æ–‡ä»¶æ—¶å‘ç”Ÿå¼‚å¸¸ï¼š{str(e)}")
     
    def get_img_doing(self):
        """è·å–å›¾åƒ"""
        try:
            face_name = self.lineEdit_face_name.text()
            
            if face_name == "è¯·åœ¨æ­¤è¾“å…¥äººè„¸å" or face_name == "":
                self.label_loadface.setText("è¯·å…ˆè¾“å…¥äººè„¸åç§°ï¼")
                return
            
            if self.current_face is None:
                self.label_loadface.setText("æ²¡æœ‰æ£€æµ‹åˆ°äººè„¸ï¼Œè¯·å…ˆé€‰æ‹©å›¾ç‰‡æˆ–ä½¿ç”¨æ‘„åƒå¤´ï¼")
                return
            
            if not self.current_face.any():
                self.label_loadface.setText("äººè„¸æ•°æ®æ— æ•ˆï¼Œè¯·é‡æ–°é€‰æ‹©å›¾ç‰‡ï¼")
                return
            
            cur_path = self.path_face_dir + face_name + "/"
            
            if not os.path.exists(cur_path):
                try:
                    os.makedirs(cur_path, exist_ok=True)
                    self.label_new_res.setText("å·²è‡ªåŠ¨åˆ›å»ºäººè„¸æ–‡ä»¶å¤¹ï¼")
                except Exception as e:
                    self.label_loadface.setText(f"åˆ›å»ºç›®å½•å¤±è´¥ï¼š{str(e)}")
                    return
            
            try:
                files_path = glob.glob(pathname=cur_path + face_name + '_*.jpg')
                img_num = len(files_path) + 1
                
                success, encoded_img = cv2.imencode(".jpg", self.current_face)
                if not success:
                    self.label_loadface.setText("å›¾ç‰‡ç¼–ç å¤±è´¥ï¼")
                    return
                
                file_path = cur_path + face_name + "_" + str(img_num) + ".jpg"
                encoded_img.tofile(file_path)
                self.label_loadface.setText("å›¾ç‰‡" + face_name + "_" + str(img_num) + ".jpg" + "å·²ä¿å­˜ï¼Œè¯·ç»§ç»­æ·»åŠ æˆ–å½•å…¥ï¼")
                
                files_path = glob.glob(pathname=cur_path + face_name + '_*.jpg')
                self.disp_load_face(self.current_face)
                self.current_face = None
                self.toolButton_get_pic.setEnabled(False)

                if len(files_path) > 0:
                    self.toolButton_load_pic.setEnabled(True)
            except Exception as e:
                self.label_loadface.setText(f"ä¿å­˜å›¾ç‰‡å¤±è´¥ï¼š{str(e)}")
                return
        except Exception as e:
            self.label_loadface.setText(f"ä¿å­˜äººè„¸æ—¶å‘ç”Ÿå¼‚å¸¸ï¼š{str(e)}")
     
    def load_img_doing(self):
        """åŠ è½½å›¾åƒ"""
        try:
            if self.timer_camera_load.isActive():
                self.timer_camera_load.stop()
            if self.cap:
                self.cap.release()

            if not os.path.exists(self.path_face_dir):
                print(f"äººè„¸æ•°æ®ç›®å½•ä¸å­˜åœ¨: {self.path_face_dir}")
                self.label_loadface.setText("äººè„¸æ•°æ®ç›®å½•ä¸å­˜åœ¨ï¼")
                return
            
            person_list = os.listdir(self.path_face_dir)

            with open("../data/features_all.csv", "w", newline="", encoding="utf-8") as csvfile:
                writer = csv.writer(csvfile)
                for person in person_list:
                    features_list = []
                    person_path = self.path_face_dir + "/" + person
                    if not os.path.isdir(person_path):
                        continue
                    
                    photos_list = os.listdir(person_path)
                    if photos_list:
                        for photo in photos_list:
                            photo_path = person_path + "/" + photo
                            if not photo.lower().endswith(('.jpg', '.jpeg', '.png')):
                                continue
                            
                            features_128D = self.extract_features(photo_path)
                            self.label_loadface.setText("å›¾ç‰‡" + photo + "å·²å½•å…¥ï¼")
                            QtWidgets.QApplication.processEvents()

                            if features_128D == 0:
                                continue
                            else:
                                features_list.append(features_128D)
                    if features_list:
                        features_mean = np.array(features_list).mean(axis=0)
                    else:
                        features_mean = np.zeros(128, dtype=int, order='C')
                    str_face = [person]
                    str_face.extend(list(features_mean))
                    writer.writerow(str_face)
                self.label_loadface.setText("å·²å®Œæˆäººè„¸å½•å…¥ï¼")
        except Exception as e:
            print(f"åŠ è½½äººè„¸æ•°æ®å¼‚å¸¸: {str(e)}")
            self.label_loadface.setText(f"åŠ è½½å¤±è´¥: {str(e)}")
     
    def extract_features(self, path_img):
        """æå–äººè„¸ç‰¹å¾"""
        try:
            img_rd = self.cv_imread(path_img)
            if img_rd is None:
                print(f"æ— æ³•è¯»å–å›¾åƒ: {path_img}")
                return 0
            
            faces = self.detector(img_rd, 1)
            if len(faces) != 0:
                shape = self.predictor(img_rd, faces[0])
                face_descriptor = self.face_reco_model.compute_face_descriptor(img_rd, shape)
            else:
                face_descriptor = 0
            return face_descriptor
        except Exception as e:
            print(f"ç‰¹å¾æå–å¼‚å¸¸ ({path_img}): {str(e)}")
            return 0
     
    def disp_img(self, image):
        """æ˜¾ç¤ºå›¾åƒ"""
        try:
            if image is not None:
                image = cv2.resize(image, (500, 500))
                show = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                showImage = QtGui.QImage(show.data, show.shape[1], show.shape[0], QtGui.QImage.Format_RGB888)
                a = QtGui.QPixmap.fromImage(showImage)
                self.label_display.setPixmap(a)
                self.label_display.setScaledContents(True)
                QtWidgets.QApplication.processEvents()
        except Exception as e:
            print(f"æ˜¾ç¤ºå›¾åƒå¼‚å¸¸: {str(e)}")
     
    def disp_face(self, image):
        """æ˜¾ç¤ºäººè„¸"""
        self.label_pic_newface.clear()
        try:
            if image is not None and image.any():
                image = cv2.resize(image, (200, 200))
                show = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                showImage = QtGui.QImage(show.data, show.shape[1], show.shape[0], QtGui.QImage.Format_RGB888)
                a = QtGui.QPixmap.fromImage(showImage)
                self.label_pic_newface.setPixmap(a)
                self.label_pic_newface.setScaledContents(True)
                QtWidgets.QApplication.processEvents()
        except Exception as e:
            print(f"æ˜¾ç¤ºäººè„¸å›¾åƒå¼‚å¸¸: {str(e)}")
     
    def disp_load_face(self, image):
        """æ˜¾ç¤ºåŠ è½½çš„äººè„¸"""
        try:
            if image is not None:
                image = cv2.resize(image, (500, 500))
                show = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
                showImage = QtGui.QImage(show.data, show.shape[1], show.shape[0], QtGui.QImage.Format_RGB888)
                a = QtGui.QPixmap.fromImage(showImage)
                self.label_pic_org.setPixmap(a)
                self.label_pic_org.setScaledContents(True)
                QtWidgets.QApplication.processEvents()
        except Exception as e:
            print(f"æ˜¾ç¤ºåŠ è½½å›¾åƒå¼‚å¸¸: {str(e)}")
     
    def change_table(self, path, res, time_now, distance):
        """æ›´æ–°è¡¨æ ¼è®°å½•"""
        self.count += 1
        if self.count > 6:
            self.tableWidget_rec.setRowCount(self.count)
        
        # æ·»åŠ è¡¨æ ¼é¡¹
        items = [str(self.count), path, res, time_now, str(round(distance, 4))]
        for i, item_text in enumerate(items):
            newItem = QTableWidgetItem(item_text)
            newItem.setTextAlignment(Qt.AlignCenter)
            self.tableWidget_rec.setItem(self.count - 1, i, newItem)
            self.tableWidget_rec.setCurrentItem(newItem)
    
    def get_face_database(self):
        """è·å–äººè„¸æ•°æ®åº“"""
        try:
            if os.path.exists("../data/features_all.csv"):
                with open("../data/features_all.csv", "r", encoding="utf-8") as csvfile:
                    reader = csv.reader(csvfile)
                    self.face_feature_exist = []
                    self.face_name_exist = []
                    for row in reader:
                        if row:
                            self.face_name_exist.append(row[0])
                            features = [float(x) for x in row[1:]]
                            self.face_feature_exist.append(features)
                return True
            return False
        except Exception as e:
            print(f"è·å–äººè„¸æ•°æ®åº“å¼‚å¸¸: {str(e)}")
            return False
    
    def update_face(self):
        """æ›´æ–°äººè„¸æ•°æ®"""
        try:
            if os.path.exists("../data/features_all.csv"):
                with open("../data/features_all.csv", "r", encoding="utf-8") as csvfile:
                    reader = csv.reader(csvfile)
                    self.tableWidget_mana.setRowCount(0)
                    for i, row in enumerate(reader):
                        if row:
                            self.tableWidget_mana.insertRow(i)
                            self.tableWidget_mana.setItem(i, 0, QTableWidgetItem(str(i + 1)))
                            self.tableWidget_mana.setItem(i, 1, QTableWidgetItem(row[0]))
                            self.tableWidget_mana.setItem(i, 2, QTableWidgetItem("å·²å½•å…¥"))
                            self.tableWidget_mana.setItem(i, 3, QTableWidgetItem("æ­£å¸¸"))
        except Exception as e:
            print(f"æ›´æ–°äººè„¸æ•°æ®å¼‚å¸¸: {str(e)}")
    
    def do_update_face(self):
        """åˆ·æ–°äººè„¸æ•°æ®æ˜¾ç¤º"""
        self.update_face()
    
    def button_open_camera_load(self):
        """æ‰“å¼€æ‘„åƒå¤´å½•å…¥"""
        try:
            if not self.timer_camera_load.isActive():
                flag = self.cap.open(self.CAM_NUM)
                if not flag:
                    QtWidgets.QMessageBox.warning(self.centralwidget, "è­¦å‘Š", "è¯·æ£€æµ‹ç›¸æœºä¸ç”µè„‘æ˜¯å¦è¿æ¥æ­£ç¡®ï¼")
                else:
                    self.timer_camera_load.start(30)
                    self.label_loadface.setText("æ‘„åƒå¤´å·²æ‰“å¼€ï¼Œæ£€æµ‹åˆ°äººè„¸åå¯ç‚¹å‡»å–å›¾æŒ‰é’®")
            else:
                self.timer_camera_load.stop()
                self.cap.release()
                self.label_display.clear()
                self.gif_movie()
                self.label_loadface.setText("æ‘„åƒå¤´å·²å…³é—­")
        except Exception as e:
            print(f"æ‘„åƒå¤´å½•å…¥å¼‚å¸¸: {str(e)}")
    
    def show_camera_load(self):
        """æ˜¾ç¤ºæ‘„åƒå¤´å½•å…¥ç”»é¢"""
        try:
            flag, image = self.cap.read()
            if flag:
                show_image = cv2.resize(image, (500, 500))
                
                # æ£€æµ‹äººè„¸
                faces = self.detector(image, 0)
                if len(faces) != 0:
                    for k, d in enumerate(faces):
                        height = (d.bottom() - d.top())
                        width = (d.right() - d.left())
                        hh = int(height / 2)
                        ww = int(width / 2)
                        
                        y2 = d.right() + ww
                        x2 = d.bottom() + hh
                        y1 = d.left() - ww
                        x1 = d.top() - hh
                        
                        if y2 > image.shape[1]: y2 = image.shape[1]
                        elif x2 > image.shape[0]: x2 = image.shape[0]
                        elif y1 < 0: y1 = 0
                        elif x1 < 0: x1 = 0
                        
                        crop_face = image[x1: x2, y1: y2]
                        if crop_face.size > 0:
                            self.current_face = crop_face
                            self.disp_face(crop_face)
                            
                            face_name = self.lineEdit_face_name.text()
                            if face_name != "è¯·åœ¨æ­¤è¾“å…¥äººè„¸å" and face_name != "":
                                self.toolButton_get_pic.setEnabled(True)
                                self.label_loadface.setText("æ£€æµ‹åˆ°äººè„¸ï¼Œå¯ç‚¹å‡»å–å›¾æŒ‰é’®ä¿å­˜")
                        
                        # åœ¨æ˜¾ç¤ºå›¾åƒä¸Šç»˜åˆ¶äººè„¸æ¡†
                        cv2.rectangle(show_image, (d.left(), d.top()), (d.right(), d.bottom()), (0, 255, 0), 2)
                
                show = cv2.cvtColor(show_image, cv2.COLOR_BGR2RGB)
                showImage = QtGui.QImage(show.data, show.shape[1], show.shape[0], QtGui.QImage.Format_RGB888)
                pixmap = QtGui.QPixmap.fromImage(showImage)
                self.label_display.setPixmap(pixmap)
                self.label_display.setScaledContents(True)
        except Exception as e:
            print(f"æ‘„åƒå¤´æ˜¾ç¤ºå¼‚å¸¸: {str(e)}")
    
    def table_review(self, row, col):
        """è¡¨æ ¼ç‚¹å‡»äº‹ä»¶"""
        try:
            if row >= 0:
                name = self.tableWidget_mana.item(row, 1).text()
                face_dir = self.path_face_dir + name
                if os.path.exists(face_dir):
                    files = glob.glob(face_dir + "/*.jpg")
                    if files:
                        img = self.cv_imread(files[0])
                        if img is not None:
                            self.disp_img(img)
        except Exception as e:
            print(f"è¡¨æ ¼ç‚¹å‡»äº‹ä»¶å¼‚å¸¸: {str(e)}")
    
    def delete_doing(self):
        """åˆ é™¤äººè„¸æ•°æ®"""
        try:
            current_row = self.tableWidget_mana.currentRow()
            if current_row >= 0:
                name = self.tableWidget_mana.item(current_row, 1).text()
                reply = QtWidgets.QMessageBox.question(self.centralwidget, 'ç¡®è®¤åˆ é™¤', 
                                                      f'ç¡®å®šè¦åˆ é™¤ {name} çš„äººè„¸æ•°æ®å—ï¼Ÿ',
                                                      QtWidgets.QMessageBox.Yes | QtWidgets.QMessageBox.No,
                                                      QtWidgets.QMessageBox.No)
                if reply == QtWidgets.QMessageBox.Yes:
                    face_dir = self.path_face_dir + name
                    if os.path.exists(face_dir):
                        shutil.rmtree(face_dir)
                    self.update_face()
                    QtWidgets.QMessageBox.information(self.centralwidget, 'åˆ é™¤æˆåŠŸ', f'{name} çš„äººè„¸æ•°æ®å·²åˆ é™¤')
        except Exception as e:
            print(f"åˆ é™¤äººè„¸æ•°æ®å¼‚å¸¸: {str(e)}")
            QtWidgets.QMessageBox.warning(self.centralwidget, 'åˆ é™¤å¤±è´¥', f'åˆ é™¤å¤±è´¥: {str(e)}')
    
    def show_camera(self):
        """æ ‡å‡†æ‘„åƒå¤´å¤„ç†å‡½æ•°"""
        try:
            start_time = time.time()
            flag, img_rd = self.cap.read()  # è·å–ç”»é¢
            if not flag or img_rd is None:
                print("æ‘„åƒå¤´è¯»å–å¤±è´¥")
                return
        except Exception as e:
            print(f"æ‘„åƒå¤´è¯»å–å¼‚å¸¸: {str(e)}")
            return
        
        try:
            image = img_rd.copy()
            # æ£€æµ‹äººè„¸
            faces = self.detector(img_rd, 0)
            self.label_score_num.setText(str(len(faces)))

            # Update cnt for faces in frames
            self.last_face_cnt = self.current_face_cnt
            self.current_face_cnt = len(faces)

            # Update the face name list in last frame
            self.last_face_name = self.current_face_name[:]

            # update frame centroid list
            self.last_centroid = self.current_centroid
            self.current_centroid = []

            # 2.1. if cnt not changes
            if (self.current_face_cnt == self.last_face_cnt) and (
                    self.reclassify_cnt != self.reclassify_interval):

                self.current_face_position = []

                if "æœªçŸ¥äººè„¸" in self.current_face_name:
                    self.reclassify_cnt += 1

                if self.current_face_cnt != 0:
                    # 2.1.1 Get ROI positions
                    for k, d in enumerate(faces):
                        self.current_face_position.append(tuple(
                            [faces[k].left(), int(faces[k].bottom() + (faces[k].bottom() - faces[k].top()) / 4)]))
                        self.current_centroid.append(
                            [int(faces[k].left() + faces[k].right()) / 2,
                             int(faces[k].top() + faces[k].bottom()) / 2])

                        # è®¡ç®—çŸ©å½¢æ¡†å¤§å°
                        y2 = d.right()
                        x2 = d.bottom()
                        y1 = d.left()
                        x1 = d.top()
                        # åˆ¤æ–­äººè„¸åŒºåŸŸæ˜¯å¦è¶…å‡ºç”»é¢èŒƒå›´
                        if y2 > img_rd.shape[1]:
                            y2 = img_rd.shape[1]
                        elif x2 > img_rd.shape[0]:
                            x2 = img_rd.shape[0]
                        elif y1 < 0:
                            y1 = 0
                        elif x1 < 0:
                            x1 = 0

                        # å‰ªåˆ‡å‡ºäººè„¸
                        crop_face = img_rd[x1: x2, y1: y2]
                        self.current_face = crop_face
                        self.disp_face(crop_face)  # åœ¨å³ä¾§labelä¸­æ˜¾ç¤ºæ£€æµ‹å‡ºçš„äººè„¸

                        rect = (d.left(), d.top(), d.right(), d.bottom())
                        name_lab = self.current_face_name[k] if self.current_face_name != [] else ""
                        image = self.drawRectBox(image, rect, name_lab)
                        self.label_plate_result.setText(name_lab)

                self.disp_img(image)  # åœ¨ç”»é¢ä¸­æ˜¾ç¤ºå›¾åƒ

                # Multi-faces in current frame, use centroid-tracker to track
                if self.current_face_cnt != 1:
                    self.centroid_tracker()

            # 2.2 If cnt of faces changes, 0->1 or 1->0 or ...
            else:
                self.current_face_position = []
                self.current_face_distance = []
                self.current_face_feature = []
                self.reclassify_cnt = 0

                # 2.2.1 Face cnt decreases: 1->0, 2->1, ...
                if self.current_face_cnt == 0:
                    # clear list of names and features
                    self.current_face_name = []
                # 2.2.2 Face cnt increase: 0->1, 0->2, ..., 1->2, ...
                else:
                    self.current_face_name = []
                    for i in range(len(faces)):
                        shape = self.predictor(img_rd, faces[i])
                        self.current_face_feature.append(
                            self.face_reco_model.compute_face_descriptor(img_rd, shape))
                        self.current_face_name.append("æœªçŸ¥äººè„¸")

                    # 2.2.2.1 éå†æ•è·åˆ°çš„å›¾åƒä¸­æ‰€æœ‰çš„äººè„¸
                    for k in range(len(faces)):
                        self.current_centroid.append(
                            [int(faces[k].left() + faces[k].right()) / 2,
                             int(faces[k].top() + faces[k].bottom()) / 2])

                        self.current_face_distance = []

                        # 2.2.2.2 æ¯ä¸ªæ•è·äººè„¸çš„åå­—åæ ‡
                        self.current_face_position.append(tuple(
                            [faces[k].left(), int(faces[k].bottom() + (faces[k].bottom() - faces[k].top()) / 4)]))

                        # 2.2.2.3 å¯¹äºæŸå¼ äººè„¸ï¼Œéå†æ‰€æœ‰å­˜å‚¨çš„äººè„¸ç‰¹å¾
                        for i in range(len(self.face_feature_exist)):
                            # å¦‚æœæ•°æ®ä¸ä¸ºç©º
                            if str(self.face_feature_exist[i][0]) != '0.0':
                                e_distance_tmp = self.euclidean_distance(
                                    self.current_face_feature[k],
                                    self.face_feature_exist[i])
                                self.current_face_distance.append(e_distance_tmp)
                            else:
                                # ç©ºæ•°æ® person_X
                                self.current_face_distance.append(999999999)

                        # 2.2.2.4 å¯»æ‰¾å‡ºæœ€å°çš„æ¬§å¼è·ç¦»åŒ¹é…
                        min_dis = min(self.current_face_distance)
                        similar_person_num = self.current_face_distance.index(min_dis)

                        if min_dis < 0.4:
                            self.current_face_name[k] = self.face_name_exist[similar_person_num]
                        self.label_score_dis.setText(str(round(min_dis, 2)))
                        date_now = datetime.datetime.now().strftime('%m-%d_%H:%M:%S')
                        self.change_table(date_now + "_" + str(self.count), self.current_face_name[k], date_now,
                                          min_dis)

            end_time = time.time()
            if end_time == start_time:
                use_time = 1
            else:
                use_time = end_time - start_time
            fps_rec = int(1.0 / round(use_time, 3))
            self.label_score_fps.setText(str(fps_rec))
        except Exception as e:
            print(f"äººè„¸è¯†åˆ«å¤„ç†å¼‚å¸¸: {str(e)}")
            self.label_plate_result.setText("å¤„ç†å¼‚å¸¸")
            self.label_score_fps.setText("0")
    
    def show_video(self):
        """æ ‡å‡†è§†é¢‘å¤„ç†å‡½æ•°"""
        try:
            start_time = time.time()
            flag, img_rd = self.cap_video.read()  # è·å–ç”»é¢
            if not flag or img_rd is None:
                print("è§†é¢‘è¯»å–å¤±è´¥")
                return
        except Exception as e:
            print(f"è§†é¢‘è¯»å–å¼‚å¸¸: {str(e)}")
            return
        
        try:
            image = img_rd.copy()
            # æ£€æµ‹äººè„¸
            faces = self.detector(img_rd, 0)
            self.label_score_num.setText(str(len(faces)))

            # Update cnt for faces in frames
            self.last_face_cnt = self.current_face_cnt
            self.current_face_cnt = len(faces)

            # Update the face name list in last frame
            self.last_face_name = self.current_face_name[:]

            # update frame centroid list
            self.last_centroid = self.current_centroid
            self.current_centroid = []

            # 2.1. if cnt not changes
            if (self.current_face_cnt == self.last_face_cnt) and (
                    self.reclassify_cnt != self.reclassify_interval):

                self.current_face_position = []

                if "æœªçŸ¥äººè„¸" in self.current_face_name:
                    self.reclassify_cnt += 1

                if self.current_face_cnt != 0:
                    # 2.1.1 Get ROI positions
                    for k, d in enumerate(faces):
                        self.current_face_position.append(tuple(
                            [faces[k].left(), int(faces[k].bottom() + (faces[k].bottom() - faces[k].top()) / 4)]))
                        self.current_centroid.append(
                            [int(faces[k].left() + faces[k].right()) / 2,
                             int(faces[k].top() + faces[k].bottom()) / 2])

                        y2 = d.right()
                        x2 = d.bottom()
                        y1 = d.left()
                        x1 = d.top()
                        # åˆ¤æ–­äººè„¸åŒºåŸŸæ˜¯å¦è¶…å‡ºç”»é¢èŒƒå›´
                        if y2 > img_rd.shape[1]:
                            y2 = img_rd.shape[1]
                        elif x2 > img_rd.shape[0]:
                            x2 = img_rd.shape[0]
                        elif y1 < 0:
                            y1 = 0
                        elif x1 < 0:
                            x1 = 0

                        # å‰ªåˆ‡å‡ºäººè„¸
                        crop_face = img_rd[x1: x2, y1: y2]
                        self.current_face = crop_face
                        self.disp_face(crop_face)  # åœ¨å³ä¾§labelä¸­æ˜¾ç¤ºæ£€æµ‹å‡ºçš„äººè„¸

                        rect = (d.left(), d.top(), d.right(), d.bottom())
                        name_lab = self.current_face_name[k] if self.current_face_name != [] else ""
                        image = self.drawRectBox(image, rect, name_lab)
                        self.label_plate_result.setText(name_lab)

                self.disp_img(image)  # åœ¨ç”»é¢ä¸­æ˜¾ç¤ºå›¾åƒ

                # Multi-faces in current frame, use centroid-tracker to track
                if self.current_face_cnt != 1:
                    self.centroid_tracker()

            # 2.2 If cnt of faces changes, 0->1 or 1->0 or ...
            else:
                self.current_face_position = []
                self.current_face_distance = []
                self.current_face_feature = []
                self.reclassify_cnt = 0

                # 2.2.1 Face cnt decreases: 1->0, 2->1, ...
                if self.current_face_cnt == 0:
                    # clear list of names and features
                    self.current_face_name = []
                # 2.2.2 Face cnt increase: 0->1, 0->2, ..., 1->2, ...
                else:
                    self.current_face_name = []
                    for i in range(len(faces)):
                        shape = self.predictor(img_rd, faces[i])
                        self.current_face_feature.append(
                            self.face_reco_model.compute_face_descriptor(img_rd, shape))
                        self.current_face_name.append("æœªçŸ¥äººè„¸")

                    # 2.2.2.1 éå†æ•è·åˆ°çš„å›¾åƒä¸­æ‰€æœ‰çš„äººè„¸
                    for k in range(len(faces)):
                        self.current_centroid.append(
                            [int(faces[k].left() + faces[k].right()) / 2,
                             int(faces[k].top() + faces[k].bottom()) / 2])

                        self.current_face_distance = []

                        # 2.2.2.2 æ¯ä¸ªæ•è·äººè„¸çš„åå­—åæ ‡
                        self.current_face_position.append(tuple(
                            [faces[k].left(), int(faces[k].bottom() + (faces[k].bottom() - faces[k].top()) / 4)]))

                        # 2.2.2.3 å¯¹äºæŸå¼ äººè„¸ï¼Œéå†æ‰€æœ‰å­˜å‚¨çš„äººè„¸ç‰¹å¾
                        for i in range(len(self.face_feature_exist)):
                            # å¦‚æœæ•°æ®ä¸ä¸ºç©º
                            if str(self.face_feature_exist[i][0]) != '0.0':
                                e_distance_tmp = self.euclidean_distance(
                                    self.current_face_feature[k],
                                    self.face_feature_exist[i])
                                self.current_face_distance.append(e_distance_tmp)
                            else:
                                # ç©ºæ•°æ® person_X
                                self.current_face_distance.append(999999999)

                        # 2.2.2.4 å¯»æ‰¾å‡ºæœ€å°çš„æ¬§å¼è·ç¦»åŒ¹é…
                        min_dis = min(self.current_face_distance)
                        similar_person_num = self.current_face_distance.index(min_dis)

                        if min_dis < 0.4:
                            self.current_face_name[k] = self.face_name_exist[similar_person_num]
                        self.label_score_dis.setText(str(round(min_dis, 2)))
                        # å°†è¯†åˆ«è®°å½•åˆ°è¡¨æ ¼ä¸­
                        date_now = datetime.datetime.now().strftime('%m-%d_%H:%M:%S')
                        self.change_table(date_now + "_" + str(self.count), self.current_face_name[k], date_now,
                                          min_dis)

            end_time = time.time()
            if end_time - start_time == 0:
                use_time = 1
            else:
                use_time = end_time - start_time
            fps_rec = int(1.0 / round(use_time, 3))
            self.label_score_fps.setText(str(fps_rec))
        except Exception as e:
            print(f"è§†é¢‘å¤„ç†å¼‚å¸¸: {str(e)}")
            self.label_plate_result.setText("å¤„ç†å¼‚å¸¸")
            self.label_score_fps.setText("0")
    
    def centroid_tracker(self):
        """è´¨å¿ƒè·Ÿè¸ªå™¨"""
        for i in range(len(self.current_centroid)):
            distance_current_person = []
            # è®¡ç®—ä¸åŒå¯¹è±¡é—´çš„è·ç¦»
            for j in range(len(self.last_centroid)):
                self.last_current_distance = self.euclidean_distance(
                    self.current_centroid[i], self.last_centroid[j])
                distance_current_person.append(self.last_current_distance)

            last_frame_num = distance_current_person.index(
                min(distance_current_person))
            self.current_face_name[i] = self.last_face_name[last_frame_num]

if __name__ == "__main__":
    print("\n=== å¢å¼ºç‰ˆäººè„¸è¯†åˆ«ç³»ç»Ÿ ===")
    print("ä¸»è¦æ”¹è¿›:")
    print("âœ“ ArcFaceæŸå¤±å‡½æ•° - æå‡è¯†åˆ«å‡†ç¡®æ€§")
    print("âœ“ æ³¨æ„åŠ›æœºåˆ¶(CBAM) - å¤„ç†é®æŒ¡æƒ…å†µ")
    print("âœ“ ä½å…‰ç…§å¢å¼º - CLAHEç®—æ³•")
    print("âœ“ å¤šå°ºåº¦æ£€æµ‹ - æå‡æ£€æµ‹ç‡")
    print("âœ“ æ”¹è¿›é¢„å¤„ç† - æ ‡å‡†åŒ–æµç¨‹")
    print("âœ“ å¼‚å¸¸å¤„ç† - æå‡ç³»ç»Ÿç¨³å®šæ€§")
    print("\né€‚ç”¨åœºæ™¯:")
    print("â€¢ æˆ´å£ç½©äººè„¸è¯†åˆ«")
    print("â€¢ æˆ´å¸½å­äººè„¸è¯†åˆ«")
    print("â€¢ æš—å…‰ç¯å¢ƒè¯†åˆ«")
    print("â€¢ éƒ¨åˆ†é®æŒ¡è¯†åˆ«")
    print("\næ­£åœ¨å¯åŠ¨GUIç•Œé¢...")
    
    # å¯åŠ¨PyQt5åº”ç”¨ç¨‹åº
    import sys
    app = QtWidgets.QApplication(sys.argv)
    MainWindow = QtWidgets.QMainWindow()
    ui = Face_MainWindow(MainWindow)
    MainWindow.show()
    
    print("âœ“ å¢å¼ºç‰ˆäººè„¸è¯†åˆ«ç³»ç»ŸGUIå·²å¯åŠ¨")
    print("\nä½¿ç”¨è¯´æ˜:")
    print("1. ç‚¹å‡»'å½•å…¥'æŒ‰é’®æ·»åŠ æ–°çš„äººè„¸")
    print("2. ç‚¹å‡»'è¯†åˆ«'æŒ‰é’®è¿›è¡Œäººè„¸è¯†åˆ«")
    print("3. ç‚¹å‡»'ç®¡ç†'æŒ‰é’®ç®¡ç†å·²æœ‰äººè„¸æ•°æ®")
    print("4. ç³»ç»Ÿä¼šè‡ªåŠ¨ä½¿ç”¨å¢å¼ºç®—æ³•æå‡è¯†åˆ«å‡†ç¡®æ€§")
    
    sys.exit(app.exec_())