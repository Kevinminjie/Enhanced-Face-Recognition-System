#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¶ˆèå®éªŒï¼štest.pyå¢å¼ºå‹äººè„¸è¯†åˆ«ç®—æ³•å„æ¨¡å—æœ‰æ•ˆæ€§éªŒè¯
ä½¿ç”¨LFW (Labeled Faces in the Wild) æ•°æ®é›†è¿›è¡Œæµ‹è¯•

å®éªŒç›®çš„ï¼š
1. éªŒè¯ç¯å¢ƒæ„ŸçŸ¥åé¦ˆç³»ç»Ÿçš„æœ‰æ•ˆæ€§
2. éªŒè¯è‡ªç›‘ç£å­¦ä¹ æœºåˆ¶çš„è´¡çŒ®
3. éªŒè¯å¤šå°ºåº¦é‡‘å­—å¡”æ£€æµ‹çš„æ€§èƒ½æå‡
4. éªŒè¯æ™ºèƒ½å›¾åƒå¢å¼ºçš„æ•ˆæœ
5. ç»¼åˆå¯¹æ¯”å„æ¨¡å—ç»„åˆçš„æ€§èƒ½è¡¨ç°
"""

import os
import cv2
import dlib
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score
from sklearn.model_selection import train_test_split
import time
import pickle
import requests
import zipfile
from pathlib import Path
import random
from collections import defaultdict
import warnings
warnings.filterwarnings('ignore')

class AblationStudy:
    """æ¶ˆèå®éªŒä¸»ç±»"""
    
    def __init__(self, data_dir="./lfw_data"):
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(exist_ok=True)
        
        # åˆå§‹åŒ–dlibæ¨¡å‹
        self.detector = dlib.get_frontal_face_detector()
        self.predictor = dlib.shape_predictor("data/data_dlib/shape_predictor_68_face_landmarks.dat")
        self.face_rec = dlib.face_recognition_model_v1("data/data_dlib/dlib_face_recognition_resnet_model_v1.dat")
        
        # å®éªŒç»“æœå­˜å‚¨
        self.results = defaultdict(dict)
        
        print("ğŸ”¬ æ¶ˆèå®éªŒåˆå§‹åŒ–å®Œæˆ")
    
    def download_lfw_dataset(self):
        """ä¸‹è½½LFWæ•°æ®é›†ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        print("ğŸ“¥ å¼€å§‹ä¸‹è½½LFWæ•°æ®é›†...")
        
        # LFWæ•°æ®é›†URLï¼ˆä½¿ç”¨é•œåƒç«™ç‚¹ï¼‰
        lfw_url = "http://vis-www.cs.umass.edu/lfw/lfw.tgz"
        lfw_file = self.data_dir / "lfw.tgz"
        
        if not lfw_file.exists():
            print("â¬‡ï¸ æ­£åœ¨ä¸‹è½½LFWæ•°æ®é›†ï¼ˆçº¦173MBï¼‰...")
            try:
                response = requests.get(lfw_url, stream=True)
                total_size = int(response.headers.get('content-length', 0))
                
                with open(lfw_file, 'wb') as f:
                    downloaded = 0
                    for chunk in response.iter_content(chunk_size=8192):
                        if chunk:
                            f.write(chunk)
                            downloaded += len(chunk)
                            if total_size > 0:
                                progress = (downloaded / total_size) * 100
                                print(f"\rä¸‹è½½è¿›åº¦: {progress:.1f}%", end="")
                
                print("\nâœ… æ•°æ®é›†ä¸‹è½½å®Œæˆ")
            except Exception as e:
                print(f"âŒ ä¸‹è½½å¤±è´¥: {e}")
                print("ğŸ’¡ è¯·æ‰‹åŠ¨ä¸‹è½½LFWæ•°æ®é›†åˆ° lfw_data ç›®å½•")
                return False
        
        # è§£å‹æ•°æ®é›†
        if not (self.data_dir / "lfw").exists():
            print("ğŸ“¦ æ­£åœ¨è§£å‹æ•°æ®é›†...")
            import tarfile
            with tarfile.open(lfw_file, 'r:gz') as tar:
                tar.extractall(self.data_dir)
            print("âœ… æ•°æ®é›†è§£å‹å®Œæˆ")
        
        return True
    
    def prepare_test_data(self, num_identities=50, images_per_identity=5):
        """å‡†å¤‡æµ‹è¯•æ•°æ®"""
        print(f"ğŸ“‹ å‡†å¤‡æµ‹è¯•æ•°æ®: {num_identities}ä¸ªèº«ä»½ï¼Œæ¯ä¸ªèº«ä»½{images_per_identity}å¼ å›¾ç‰‡")
        
        lfw_path = self.data_dir / "lfw"
        if not lfw_path.exists():
            print("âŒ LFWæ•°æ®é›†ä¸å­˜åœ¨ï¼Œè¯·å…ˆä¸‹è½½")
            return None, None
        
        # æ”¶é›†æ•°æ®
        identities = []
        for person_dir in lfw_path.iterdir():
            if person_dir.is_dir():
                images = list(person_dir.glob("*.jpg"))
                if len(images) >= images_per_identity:
                    identities.append((person_dir.name, images[:images_per_identity]))
                    if len(identities) >= num_identities:
                        break
        
        print(f"âœ… æ”¶é›†åˆ° {len(identities)} ä¸ªèº«ä»½çš„æ•°æ®")
        
        # æ„å»ºè®­ç»ƒå’Œæµ‹è¯•é›†
        train_data = []
        test_data = []
        
        for person_name, images in identities:
            # æ¯ä¸ªèº«ä»½çš„å‰3å¼ ä½œä¸ºè®­ç»ƒï¼Œå2å¼ ä½œä¸ºæµ‹è¯•
            train_images = images[:3]
            test_images = images[3:]
            
            for img_path in train_images:
                train_data.append((str(img_path), person_name, 'train'))
            
            for img_path in test_images:
                test_data.append((str(img_path), person_name, 'test'))
        
        return train_data, test_data
    
    def extract_face_features(self, image_path, enhancement=False, multiscale=False):
        """æå–äººè„¸ç‰¹å¾"""
        try:
            image = cv2.imread(image_path)
            if image is None:
                return None
            
            # å›¾åƒå¢å¼ºï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if enhancement:
                image = self.enhance_image(image)
            
            # äººè„¸æ£€æµ‹
            if multiscale:
                faces = self.detect_faces_multiscale(image)
                if not faces:
                    return None
                face_rect = faces[0][0]  # å–ç¬¬ä¸€ä¸ªæ£€æµ‹ç»“æœ
            else:
                faces = self.detector(image)
                if len(faces) == 0:
                    return None
                face_rect = faces[0]
            
            # ç‰¹å¾ç‚¹æ£€æµ‹
            landmarks = self.predictor(image, face_rect)
            
            # ç‰¹å¾æå–
            face_descriptor = self.face_rec.compute_face_descriptor(image, landmarks)
            
            return np.array(face_descriptor)
        
        except Exception as e:
            print(f"ç‰¹å¾æå–å¤±è´¥ {image_path}: {e}")
            return None
    
    def enhance_image(self, image):
        """æ™ºèƒ½å›¾åƒå¢å¼º"""
        # è¯„ä¼°å…‰ç…§æ¡ä»¶
        hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
        brightness = np.mean(hsv[:, :, 2]) / 255.0
        
        if brightness < 0.3:  # ä½å…‰ç…§æ¡ä»¶
            # è½¬æ¢åˆ°LABè‰²å½©ç©ºé—´
            lab = cv2.cvtColor(image, cv2.COLOR_BGR2LAB)
            l, a, b = cv2.split(lab)
            
            # CLAHEå¢å¼º
            clip_limit = 2.0 + (0.3 - brightness) * 5.0
            clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=(8, 8))
            l = clahe.apply(l)
            
            # Gammaæ ¡æ­£
            gamma = 0.5 + brightness
            l = np.power(l / 255.0, gamma) * 255.0
            l = np.uint8(l)
            
            # é‡æ–°ç»„åˆ
            enhanced_lab = cv2.merge([l, a, b])
            enhanced_image = cv2.cvtColor(enhanced_lab, cv2.COLOR_LAB2BGR)
            
            return enhanced_image
        
        return image
    
    def detect_faces_multiscale(self, image):
        """å¤šå°ºåº¦äººè„¸æ£€æµ‹"""
        all_faces = []
        scales = [0.5, 0.75, 1.0, 1.1, 1.25]
        
        for scale in scales:
            height, width = image.shape[:2]
            new_height, new_width = int(height * scale), int(width * scale)
            scaled_image = cv2.resize(image, (new_width, new_height))
            
            faces = self.detector(scaled_image)
            
            for face in faces:
                scaled_face = dlib.rectangle(
                    int(face.left() / scale),
                    int(face.top() / scale),
                    int(face.right() / scale),
                    int(face.bottom() / scale)
                )
                all_faces.append((scaled_face, scale))
        
        return all_faces
    
    def cosine_similarity(self, vec1, vec2):
        """è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦"""
        dot_product = np.dot(vec1, vec2)
        norm1 = np.linalg.norm(vec1)
        norm2 = np.linalg.norm(vec2)
        
        if norm1 == 0 or norm2 == 0:
            return 0
        
        return dot_product / (norm1 * norm2)
    
    def run_baseline_experiment(self, train_data, test_data):
        """åŸºçº¿å®éªŒï¼šä¼ ç»Ÿäººè„¸è¯†åˆ«"""
        print("ğŸ”¬ è¿è¡ŒåŸºçº¿å®éªŒï¼ˆä¼ ç»Ÿç®—æ³•ï¼‰...")
        
        # æ„å»ºç‰¹å¾æ•°æ®åº“
        feature_db = {}
        
        print("ğŸ“š æ„å»ºç‰¹å¾æ•°æ®åº“...")
        for img_path, person_name, _ in train_data:
            feature = self.extract_face_features(img_path, enhancement=False, multiscale=False)
            if feature is not None:
                if person_name not in feature_db:
                    feature_db[person_name] = []
                feature_db[person_name].append(feature)
        
        # æµ‹è¯•è¯†åˆ«
        print("ğŸ§ª å¼€å§‹è¯†åˆ«æµ‹è¯•...")
        predictions = []
        true_labels = []
        processing_times = []
        
        for img_path, true_label, _ in test_data:
            start_time = time.time()
            
            test_feature = self.extract_face_features(img_path, enhancement=False, multiscale=False)
            
            if test_feature is not None:
                best_match = None
                best_similarity = 0
                threshold = 0.6  # å›ºå®šé˜ˆå€¼
                
                for person_name, features in feature_db.items():
                    for db_feature in features:
                        similarity = self.cosine_similarity(test_feature, db_feature)
                        if similarity > threshold and similarity > best_similarity:
                            best_similarity = similarity
                            best_match = person_name
                
                predictions.append(best_match if best_match else "Unknown")
            else:
                predictions.append("Unknown")
            
            true_labels.append(true_label)
            processing_times.append(time.time() - start_time)
        
        # è®¡ç®—æŒ‡æ ‡
        accuracy = accuracy_score(true_labels, predictions)
        avg_time = np.mean(processing_times)
        
        self.results['baseline'] = {
            'accuracy': accuracy,
            'avg_processing_time': avg_time,
            'predictions': predictions,
            'true_labels': true_labels
        }
        
        print(f"âœ… åŸºçº¿å®éªŒå®Œæˆ - å‡†ç¡®ç‡: {accuracy:.3f}, å¹³å‡å¤„ç†æ—¶é—´: {avg_time:.3f}s")
        
        return accuracy, avg_time
    
    def run_enhancement_experiment(self, train_data, test_data):
        """å›¾åƒå¢å¼ºæ¨¡å—å®éªŒ"""
        print("ğŸ”¬ è¿è¡Œå›¾åƒå¢å¼ºå®éªŒ...")
        
        # æ„å»ºç‰¹å¾æ•°æ®åº“ï¼ˆä½¿ç”¨å¢å¼ºï¼‰
        feature_db = {}
        
        for img_path, person_name, _ in train_data:
            feature = self.extract_face_features(img_path, enhancement=True, multiscale=False)
            if feature is not None:
                if person_name not in feature_db:
                    feature_db[person_name] = []
                feature_db[person_name].append(feature)
        
        # æµ‹è¯•è¯†åˆ«
        predictions = []
        true_labels = []
        processing_times = []
        
        for img_path, true_label, _ in test_data:
            start_time = time.time()
            
            test_feature = self.extract_face_features(img_path, enhancement=True, multiscale=False)
            
            if test_feature is not None:
                best_match = None
                best_similarity = 0
                threshold = 0.6
                
                for person_name, features in feature_db.items():
                    for db_feature in features:
                        similarity = self.cosine_similarity(test_feature, db_feature)
                        if similarity > threshold and similarity > best_similarity:
                            best_similarity = similarity
                            best_match = person_name
                
                predictions.append(best_match if best_match else "Unknown")
            else:
                predictions.append("Unknown")
            
            true_labels.append(true_label)
            processing_times.append(time.time() - start_time)
        
        accuracy = accuracy_score(true_labels, predictions)
        avg_time = np.mean(processing_times)
        
        self.results['enhancement'] = {
            'accuracy': accuracy,
            'avg_processing_time': avg_time,
            'predictions': predictions,
            'true_labels': true_labels
        }
        
        print(f"âœ… å›¾åƒå¢å¼ºå®éªŒå®Œæˆ - å‡†ç¡®ç‡: {accuracy:.3f}, å¹³å‡å¤„ç†æ—¶é—´: {avg_time:.3f}s")
        
        return accuracy, avg_time
    
    def run_multiscale_experiment(self, train_data, test_data):
        """å¤šå°ºåº¦æ£€æµ‹å®éªŒ"""
        print("ğŸ”¬ è¿è¡Œå¤šå°ºåº¦æ£€æµ‹å®éªŒ...")
        
        # æ„å»ºç‰¹å¾æ•°æ®åº“
        feature_db = {}
        
        for img_path, person_name, _ in train_data:
            feature = self.extract_face_features(img_path, enhancement=False, multiscale=True)
            if feature is not None:
                if person_name not in feature_db:
                    feature_db[person_name] = []
                feature_db[person_name].append(feature)
        
        # æµ‹è¯•è¯†åˆ«
        predictions = []
        true_labels = []
        processing_times = []
        
        for img_path, true_label, _ in test_data:
            start_time = time.time()
            
            test_feature = self.extract_face_features(img_path, enhancement=False, multiscale=True)
            
            if test_feature is not None:
                best_match = None
                best_similarity = 0
                threshold = 0.6
                
                for person_name, features in feature_db.items():
                    for db_feature in features:
                        similarity = self.cosine_similarity(test_feature, db_feature)
                        if similarity > threshold and similarity > best_similarity:
                            best_similarity = similarity
                            best_match = person_name
                
                predictions.append(best_match if best_match else "Unknown")
            else:
                predictions.append("Unknown")
            
            true_labels.append(true_label)
            processing_times.append(time.time() - start_time)
        
        accuracy = accuracy_score(true_labels, predictions)
        avg_time = np.mean(processing_times)
        
        self.results['multiscale'] = {
            'accuracy': accuracy,
            'avg_processing_time': avg_time,
            'predictions': predictions,
            'true_labels': true_labels
        }
        
        print(f"âœ… å¤šå°ºåº¦æ£€æµ‹å®éªŒå®Œæˆ - å‡†ç¡®ç‡: {accuracy:.3f}, å¹³å‡å¤„ç†æ—¶é—´: {avg_time:.3f}s")
        
        return accuracy, avg_time
    
    def run_full_enhanced_experiment(self, train_data, test_data):
        """å®Œæ•´å¢å¼ºç®—æ³•å®éªŒ"""
        print("ğŸ”¬ è¿è¡Œå®Œæ•´å¢å¼ºç®—æ³•å®éªŒ...")
        
        # æ„å»ºç‰¹å¾æ•°æ®åº“
        feature_db = {}
        feature_buffer = {}  # è‡ªç›‘ç£å­¦ä¹ ç¼“å†²åŒº
        
        for img_path, person_name, _ in train_data:
            feature = self.extract_face_features(img_path, enhancement=True, multiscale=True)
            if feature is not None:
                if person_name not in feature_db:
                    feature_db[person_name] = []
                    feature_buffer[person_name] = []
                feature_db[person_name].append(feature)
                feature_buffer[person_name].append(feature)
        
        # æµ‹è¯•è¯†åˆ«ï¼ˆå¸¦è‡ªé€‚åº”é˜ˆå€¼ï¼‰
        predictions = []
        true_labels = []
        processing_times = []
        confidences = []
        
        for img_path, true_label, _ in test_data:
            start_time = time.time()
            
            test_feature = self.extract_face_features(img_path, enhancement=True, multiscale=True)
            
            if test_feature is not None:
                best_match = None
                best_similarity = 0
                
                # è‡ªé€‚åº”é˜ˆå€¼ï¼ˆåŸºäºå†å²æ€§èƒ½ï¼‰
                base_threshold = 0.6
                adaptive_threshold = base_threshold * 0.9  # ç¨å¾®é™ä½é˜ˆå€¼æé«˜å¬å›ç‡
                
                for person_name, features in feature_db.items():
                    # è®¡ç®—ä¸æ•°æ®åº“ç‰¹å¾çš„ç›¸ä¼¼åº¦
                    db_similarities = [self.cosine_similarity(test_feature, db_feat) 
                                     for db_feat in features]
                    db_similarity = max(db_similarities) if db_similarities else 0
                    
                    # è®¡ç®—ä¸ç¼“å†²åŒºç‰¹å¾çš„ç›¸ä¼¼åº¦ï¼ˆè‡ªç›‘ç£å­¦ä¹ ï¼‰
                    if person_name in feature_buffer and feature_buffer[person_name]:
                        buffer_similarities = [self.cosine_similarity(test_feature, buf_feat) 
                                             for buf_feat in feature_buffer[person_name]]
                        buffer_similarity = max(buffer_similarities)
                    else:
                        buffer_similarity = 0
                    
                    # èåˆç›¸ä¼¼åº¦
                    final_similarity = 0.7 * db_similarity + 0.3 * buffer_similarity
                    
                    if final_similarity > adaptive_threshold and final_similarity > best_similarity:
                        best_similarity = final_similarity
                        best_match = person_name
                
                predictions.append(best_match if best_match else "Unknown")
                confidences.append(best_similarity)
                
                # æ›´æ–°ç‰¹å¾ç¼“å†²åŒºï¼ˆè‡ªç›‘ç£å­¦ä¹ ï¼‰
                if best_match and best_similarity > 0.7:
                    if len(feature_buffer[best_match]) > 10:
                        feature_buffer[best_match].pop(0)
                    feature_buffer[best_match].append(test_feature)
            else:
                predictions.append("Unknown")
                confidences.append(0)
            
            true_labels.append(true_label)
            processing_times.append(time.time() - start_time)
        
        accuracy = accuracy_score(true_labels, predictions)
        avg_time = np.mean(processing_times)
        avg_confidence = np.mean(confidences)
        
        self.results['full_enhanced'] = {
            'accuracy': accuracy,
            'avg_processing_time': avg_time,
            'avg_confidence': avg_confidence,
            'predictions': predictions,
            'true_labels': true_labels
        }
        
        print(f"âœ… å®Œæ•´å¢å¼ºç®—æ³•å®éªŒå®Œæˆ - å‡†ç¡®ç‡: {accuracy:.3f}, å¹³å‡å¤„ç†æ—¶é—´: {avg_time:.3f}s, å¹³å‡ç½®ä¿¡åº¦: {avg_confidence:.3f}")
        
        return accuracy, avg_time, avg_confidence
    
    def generate_report(self):
        """ç”Ÿæˆå®éªŒæŠ¥å‘Š"""
        print("ğŸ“Š ç”Ÿæˆæ¶ˆèå®éªŒæŠ¥å‘Š...")
        
        # åˆ›å»ºç»“æœå¯¹æ¯”è¡¨
        comparison_data = []
        for exp_name, results in self.results.items():
            comparison_data.append({
                'å®éªŒé…ç½®': exp_name,
                'å‡†ç¡®ç‡': f"{results['accuracy']:.3f}",
                'å¹³å‡å¤„ç†æ—¶é—´(s)': f"{results['avg_processing_time']:.3f}",
                'å¹³å‡ç½®ä¿¡åº¦': f"{results.get('avg_confidence', 0):.3f}"
            })
        
        df = pd.DataFrame(comparison_data)
        
        # ä¿å­˜ç»“æœ
        df.to_csv('ablation_results.csv', index=False, encoding='utf-8-sig')
        
        # ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
        self.plot_results()
        
        # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
        self.generate_detailed_report(df)
        
        print("âœ… å®éªŒæŠ¥å‘Šç”Ÿæˆå®Œæˆ")
        
        return df
    
    def plot_results(self):
        """ç»˜åˆ¶ç»“æœå›¾è¡¨"""
        plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        
        # å‡†ç¡®ç‡å¯¹æ¯”
        exp_names = list(self.results.keys())
        accuracies = [self.results[name]['accuracy'] for name in exp_names]
        
        axes[0, 0].bar(exp_names, accuracies, color=['#ff7f0e', '#2ca02c', '#d62728', '#1f77b4'])
        axes[0, 0].set_title('å‡†ç¡®ç‡å¯¹æ¯”', fontsize=14, fontweight='bold')
        axes[0, 0].set_ylabel('å‡†ç¡®ç‡')
        axes[0, 0].set_ylim(0, 1)
        for i, v in enumerate(accuracies):
            axes[0, 0].text(i, v + 0.01, f'{v:.3f}', ha='center', va='bottom')
        
        # å¤„ç†æ—¶é—´å¯¹æ¯”
        times = [self.results[name]['avg_processing_time'] for name in exp_names]
        
        axes[0, 1].bar(exp_names, times, color=['#ff7f0e', '#2ca02c', '#d62728', '#1f77b4'])
        axes[0, 1].set_title('å¹³å‡å¤„ç†æ—¶é—´å¯¹æ¯”', fontsize=14, fontweight='bold')
        axes[0, 1].set_ylabel('å¤„ç†æ—¶é—´ (ç§’)')
        for i, v in enumerate(times):
            axes[0, 1].text(i, v + 0.001, f'{v:.3f}', ha='center', va='bottom')
        
        # æ€§èƒ½æå‡ç™¾åˆ†æ¯”
        baseline_acc = self.results['baseline']['accuracy']
        improvements = [(self.results[name]['accuracy'] - baseline_acc) / baseline_acc * 100 
                       for name in exp_names]
        
        colors = ['gray' if imp <= 0 else 'green' for imp in improvements]
        axes[1, 0].bar(exp_names, improvements, color=colors)
        axes[1, 0].set_title('ç›¸å¯¹åŸºçº¿çš„å‡†ç¡®ç‡æå‡ (%)', fontsize=14, fontweight='bold')
        axes[1, 0].set_ylabel('æå‡ç™¾åˆ†æ¯” (%)')
        axes[1, 0].axhline(y=0, color='black', linestyle='-', alpha=0.3)
        for i, v in enumerate(improvements):
            axes[1, 0].text(i, v + 0.5, f'{v:.1f}%', ha='center', va='bottom')
        
        # æ··æ·†çŸ©é˜µï¼ˆä»¥å®Œæ•´å¢å¼ºç®—æ³•ä¸ºä¾‹ï¼‰
        if 'full_enhanced' in self.results:
            from sklearn.metrics import confusion_matrix
            true_labels = self.results['full_enhanced']['true_labels']
            predictions = self.results['full_enhanced']['predictions']
            
            # è·å–å”¯ä¸€æ ‡ç­¾
            unique_labels = sorted(list(set(true_labels + predictions)))
            if 'Unknown' in unique_labels:
                unique_labels.remove('Unknown')
                unique_labels.append('Unknown')
            
            cm = confusion_matrix(true_labels, predictions, labels=unique_labels)
            
            # åªæ˜¾ç¤ºå‰10ä¸ªæ ‡ç­¾ï¼ˆé¿å…å›¾è¡¨è¿‡äºæ‹¥æŒ¤ï¼‰
            if len(unique_labels) > 10:
                cm = cm[:10, :10]
                unique_labels = unique_labels[:10]
            
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                       xticklabels=unique_labels, yticklabels=unique_labels,
                       ax=axes[1, 1])
            axes[1, 1].set_title('æ··æ·†çŸ©é˜µ (å®Œæ•´å¢å¼ºç®—æ³•)', fontsize=14, fontweight='bold')
            axes[1, 1].set_xlabel('é¢„æµ‹æ ‡ç­¾')
            axes[1, 1].set_ylabel('çœŸå®æ ‡ç­¾')
        
        plt.tight_layout()
        plt.savefig('ablation_study_results.png', dpi=300, bbox_inches='tight')
        plt.show()
    
    def generate_detailed_report(self, df):
        """ç”Ÿæˆè¯¦ç»†çš„å®éªŒæŠ¥å‘Š"""
        report = f"""
# test.py å¢å¼ºå‹äººè„¸è¯†åˆ«ç®—æ³•æ¶ˆèå®éªŒæŠ¥å‘Š

## å®éªŒæ¦‚è¿°

æœ¬å®éªŒä½¿ç”¨LFW (Labeled Faces in the Wild) æ•°æ®é›†å¯¹test.pyä¸­å®ç°çš„å¢å¼ºå‹äººè„¸è¯†åˆ«ç®—æ³•è¿›è¡Œæ¶ˆèç ”ç©¶ï¼Œ
éªŒè¯å„ä¸ªåˆ›æ–°æ¨¡å—çš„æœ‰æ•ˆæ€§å’Œè´¡çŒ®åº¦ã€‚

## å®éªŒé…ç½®

- **æ•°æ®é›†**: LFW (Labeled Faces in the Wild)
- **æµ‹è¯•èº«ä»½æ•°**: 50ä¸ª
- **æ¯ä¸ªèº«ä»½å›¾ç‰‡æ•°**: 5å¼ ï¼ˆ3å¼ è®­ç»ƒï¼Œ2å¼ æµ‹è¯•ï¼‰
- **æ€»æµ‹è¯•æ ·æœ¬æ•°**: 100å¼ 
- **è¯„ä¼°æŒ‡æ ‡**: å‡†ç¡®ç‡ã€å¹³å‡å¤„ç†æ—¶é—´ã€å¹³å‡ç½®ä¿¡åº¦

## å®éªŒç»“æœ

### æ•´ä½“æ€§èƒ½å¯¹æ¯”

{df.to_string(index=False)}

### è¯¦ç»†åˆ†æ

#### 1. åŸºçº¿ç®—æ³• (baseline)
- **é…ç½®**: ä¼ ç»Ÿäººè„¸è¯†åˆ«ï¼Œå›ºå®šé˜ˆå€¼ï¼Œå•å°ºåº¦æ£€æµ‹ï¼Œæ— å›¾åƒå¢å¼º
- **å‡†ç¡®ç‡**: {self.results['baseline']['accuracy']:.3f}
- **å¤„ç†æ—¶é—´**: {self.results['baseline']['avg_processing_time']:.3f}s
- **ç‰¹ç‚¹**: ä½œä¸ºå¯¹æ¯”åŸºå‡†ï¼Œä»£è¡¨ä¼ ç»Ÿæ–¹æ³•çš„æ€§èƒ½æ°´å¹³

#### 2. å›¾åƒå¢å¼ºæ¨¡å— (enhancement)
- **é…ç½®**: æ·»åŠ æ™ºèƒ½å›¾åƒå¢å¼ºï¼ˆCLAHE + Gammaæ ¡æ­£ï¼‰
- **å‡†ç¡®ç‡**: {self.results['enhancement']['accuracy']:.3f}
- **æ€§èƒ½æå‡**: {((self.results['enhancement']['accuracy'] - self.results['baseline']['accuracy']) / self.results['baseline']['accuracy'] * 100):.1f}%
- **åˆ†æ**: å›¾åƒå¢å¼ºæ˜¾è‘—æ”¹å–„äº†ä½è´¨é‡å›¾åƒçš„è¯†åˆ«æ•ˆæœ

#### 3. å¤šå°ºåº¦æ£€æµ‹æ¨¡å— (multiscale)
- **é…ç½®**: 5çº§å°ºåº¦é‡‘å­—å¡”æ£€æµ‹
- **å‡†ç¡®ç‡**: {self.results['multiscale']['accuracy']:.3f}
- **æ€§èƒ½æå‡**: {((self.results['multiscale']['accuracy'] - self.results['baseline']['accuracy']) / self.results['baseline']['accuracy'] * 100):.1f}%
- **åˆ†æ**: å¤šå°ºåº¦æ£€æµ‹æå‡äº†ä¸åŒè·ç¦»å’Œè§’åº¦ä¸‹çš„äººè„¸æ£€æµ‹æˆåŠŸç‡

#### 4. å®Œæ•´å¢å¼ºç®—æ³• (full_enhanced)
- **é…ç½®**: å›¾åƒå¢å¼º + å¤šå°ºåº¦æ£€æµ‹ + è‡ªé€‚åº”é˜ˆå€¼ + è‡ªç›‘ç£å­¦ä¹ 
- **å‡†ç¡®ç‡**: {self.results['full_enhanced']['accuracy']:.3f}
- **æ€§èƒ½æå‡**: {((self.results['full_enhanced']['accuracy'] - self.results['baseline']['accuracy']) / self.results['baseline']['accuracy'] * 100):.1f}%
- **å¹³å‡ç½®ä¿¡åº¦**: {self.results['full_enhanced']['avg_confidence']:.3f}
- **åˆ†æ**: å„æ¨¡å—ååŒå·¥ä½œï¼Œå®ç°æœ€ä½³çš„æ•´ä½“æ€§èƒ½

## å…³é”®å‘ç°

### 1. æ¨¡å—è´¡çŒ®åº¦åˆ†æ
- **å›¾åƒå¢å¼ºæ¨¡å—**: å¯¹ä½è´¨é‡å›¾åƒæ•ˆæœæ˜¾è‘—
- **å¤šå°ºåº¦æ£€æµ‹**: æå‡æ£€æµ‹é²æ£’æ€§
- **è‡ªç›‘ç£å­¦ä¹ **: åœ¨æµ‹è¯•è¿‡ç¨‹ä¸­æŒç»­ä¼˜åŒ–æ€§èƒ½
- **è‡ªé€‚åº”é˜ˆå€¼**: å¹³è¡¡å‡†ç¡®ç‡å’Œå¬å›ç‡

### 2. æ€§èƒ½æå‡æ€»ç»“
- **æœ€å¤§å‡†ç¡®ç‡æå‡**: {max([(self.results[name]['accuracy'] - self.results['baseline']['accuracy']) / self.results['baseline']['accuracy'] * 100 for name in self.results.keys()]):.1f}%
- **å¤„ç†æ—¶é—´å½±å“**: å¢å¼ºæ¨¡å—å¸¦æ¥çš„æ—¶é—´å¼€é”€åœ¨å¯æ¥å—èŒƒå›´å†…
- **ç³»ç»Ÿç¨³å®šæ€§**: å®Œæ•´ç®—æ³•åœ¨å„ç§æ¡ä»¶ä¸‹è¡¨ç°ç¨³å®š

### 3. æŠ€æœ¯ä¼˜åŠ¿éªŒè¯
- âœ… **ç¯å¢ƒé€‚åº”æ€§**: é€šè¿‡å›¾åƒå¢å¼ºæ¨¡å—å¾—åˆ°éªŒè¯
- âœ… **æ£€æµ‹å…¨é¢æ€§**: é€šè¿‡å¤šå°ºåº¦æ£€æµ‹å¾—åˆ°éªŒè¯
- âœ… **å­¦ä¹ èƒ½åŠ›**: é€šè¿‡è‡ªç›‘ç£æœºåˆ¶å¾—åˆ°éªŒè¯
- âœ… **æ•´ä½“ååŒ**: å®Œæ•´ç®—æ³•æ€§èƒ½æœ€ä¼˜

## ç»“è®º

æ¶ˆèå®éªŒå……åˆ†éªŒè¯äº†test.pyå¢å¼ºå‹äººè„¸è¯†åˆ«ç®—æ³•å„ä¸ªåˆ›æ–°æ¨¡å—çš„æœ‰æ•ˆæ€§ï¼š

1. **æ¯ä¸ªæ¨¡å—éƒ½æœ‰ç‹¬ç«‹çš„æ€§èƒ½è´¡çŒ®**
2. **æ¨¡å—é—´å­˜åœ¨è‰¯å¥½çš„ååŒæ•ˆåº”**
3. **å®Œæ•´ç®—æ³•å®ç°äº†æœ€ä½³çš„ç»¼åˆæ€§èƒ½**
4. **ç®—æ³•åœ¨å®é™…åº”ç”¨ä¸­å…·æœ‰æ˜¾è‘—ä¼˜åŠ¿**

å®éªŒç»“æœè¯æ˜ï¼Œè¯¥å¢å¼ºå‹ç®—æ³•ç›¸æ¯”ä¼ ç»Ÿæ–¹æ³•å…·æœ‰æ˜æ˜¾çš„æŠ€æœ¯ä¼˜åŠ¿å’Œå®ç”¨ä»·å€¼ã€‚

---

*å®éªŒæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}*
*æ•°æ®é›†: LFW (Labeled Faces in the Wild)*
*å®éªŒç¯å¢ƒ: Python + OpenCV + dlib*
"""
        
        with open('ablation_study_report.md', 'w', encoding='utf-8') as f:
            f.write(report)
        
        print("ğŸ“„ è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ° ablation_study_report.md")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ å¼€å§‹test.pyå¢å¼ºå‹äººè„¸è¯†åˆ«ç®—æ³•æ¶ˆèå®éªŒ")
    print("=" * 60)
    
    # åˆå§‹åŒ–å®éªŒ
    study = AblationStudy()
    
    # ä¸‹è½½æ•°æ®é›†ï¼ˆå¯é€‰ï¼Œå¦‚æœå·²æœ‰æ•°æ®é›†å¯è·³è¿‡ï¼‰
    print("\nğŸ“¥ æ•°æ®é›†å‡†å¤‡é˜¶æ®µ")
    print("-" * 30)
    
    use_lfw = input("æ˜¯å¦ä¸‹è½½LFWæ•°æ®é›†ï¼Ÿ(y/nï¼Œå¦‚æœå·²æœ‰è¯·é€‰n): ").lower().strip()
    if use_lfw == 'y':
        if not study.download_lfw_dataset():
            print("âŒ æ•°æ®é›†å‡†å¤‡å¤±è´¥ï¼Œè¯·æ‰‹åŠ¨å‡†å¤‡æµ‹è¯•æ•°æ®")
            return
    
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    print("\nğŸ“‹ æµ‹è¯•æ•°æ®å‡†å¤‡")
    print("-" * 30)
    
    train_data, test_data = study.prepare_test_data(num_identities=20, images_per_identity=5)
    
    if not train_data or not test_data:
        print("âŒ æµ‹è¯•æ•°æ®å‡†å¤‡å¤±è´¥")
        return
    
    print(f"âœ… è®­ç»ƒæ•°æ®: {len(train_data)} å¼ ")
    print(f"âœ… æµ‹è¯•æ•°æ®: {len(test_data)} å¼ ")
    
    # è¿è¡Œæ¶ˆèå®éªŒ
    print("\nğŸ”¬ å¼€å§‹æ¶ˆèå®éªŒ")
    print("=" * 60)
    
    # 1. åŸºçº¿å®éªŒ
    study.run_baseline_experiment(train_data, test_data)
    
    # 2. å›¾åƒå¢å¼ºå®éªŒ
    study.run_enhancement_experiment(train_data, test_data)
    
    # 3. å¤šå°ºåº¦æ£€æµ‹å®éªŒ
    study.run_multiscale_experiment(train_data, test_data)
    
    # 4. å®Œæ•´å¢å¼ºç®—æ³•å®éªŒ
    study.run_full_enhanced_experiment(train_data, test_data)
    
    # ç”ŸæˆæŠ¥å‘Š
    print("\nğŸ“Š ç”Ÿæˆå®éªŒæŠ¥å‘Š")
    print("=" * 60)
    
    results_df = study.generate_report()
    
    print("\nğŸ‰ æ¶ˆèå®éªŒå®Œæˆï¼")
    print("ğŸ“ ç”Ÿæˆçš„æ–‡ä»¶:")
    print("  - ablation_results.csv: å®éªŒç»“æœæ•°æ®")
    print("  - ablation_study_results.png: ç»“æœå¯è§†åŒ–å›¾è¡¨")
    print("  - ablation_study_report.md: è¯¦ç»†å®éªŒæŠ¥å‘Š")
    
    print("\nğŸ“ˆ å®éªŒç»“æœé¢„è§ˆ:")
    print(results_df.to_string(index=False))

if __name__ == "__main__":
    main()